{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression With Argument Level Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First I am going to do data analysis also called EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text             Label\n",
      "0  complicated 3D character models are widely use...  background_claim\n",
      "1  The range of breathtaking realistic 3D models ...  background_claim\n",
      "2         a production cannot afford major revisions  background_claim\n",
      "3  providing a flexible and efficient solution to...         own_claim\n",
      "4  Skeleton Subspace Deformation (SSD) is the pre...  background_claim\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"compiled_output.csv\")\n",
    "\n",
    "# Display the first few rows to check the structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing or empty text\n",
    "df['Text'].isnull().sum()  # Check for NaNs\n",
    "df[df['Text'].str.strip() == '']  # Check for empty or all-whitespace texts\n",
    "# Remove rows where text is empty or null\n",
    "df = df[df['Text'].str.strip() != '']\n",
    "df = df.dropna(subset=['Text'])\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), stop_words='english')  # Remove stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: complicated 3D character models are widely used in fields of entertainment, virtual reality, medicine etc\n",
      "Tokenized Text: ['complicated', '3D', 'character', 'models', 'are', 'widely', 'used', 'in', 'fields', 'of', 'entertainment,', 'virtual', 'reality,', 'medicine', 'etc']\n"
     ]
    }
   ],
   "source": [
    "# Test tokenization of a sample text\n",
    "sample_text = df['Text'].iloc[0]\n",
    "print(\"Original Text:\", sample_text)\n",
    "print(\"Tokenized Text:\", sample_text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['3d' '3d character' '3d character models' '3d models' '3d models limited'\n",
      " 'afford' 'afford major' 'afford major revisions' 'animation'\n",
      " 'animation remains' 'animation remains open' 'approach'\n",
      " 'approach character' 'approach character skinning' 'artists'\n",
      " 'artists resolution' 'artists resolution devices' 'breathtaking'\n",
      " 'breathtaking realistic' 'breathtaking realistic 3d' 'character'\n",
      " 'character models' 'character models widely' 'character skinning'\n",
      " 'character skinning present' 'complicated' 'complicated 3d'\n",
      " 'complicated 3d character' 'creativity' 'creativity artists'\n",
      " 'creativity artists resolution' 'deformation' 'deformation ssd'\n",
      " 'deformation ssd predominant' 'devices' 'efficient' 'efficient solution'\n",
      " 'efficient solution animation' 'entertainment' 'entertainment virtual'\n",
      " 'entertainment virtual reality' 'fields' 'fields entertainment'\n",
      " 'fields entertainment virtual' 'flexible' 'flexible efficient'\n",
      " 'flexible efficient solution' 'limited' 'limited creativity'\n",
      " 'limited creativity artists' 'major' 'major revisions' 'medicine'\n",
      " 'models' 'models limited' 'models limited creativity' 'models widely'\n",
      " 'models widely used' 'open' 'open problem' 'predominant'\n",
      " 'predominant approach' 'predominant approach character' 'present'\n",
      " 'problem' 'production' 'production afford' 'production afford major'\n",
      " 'providing' 'providing flexible' 'providing flexible efficient' 'range'\n",
      " 'range breathtaking' 'range breathtaking realistic' 'realistic'\n",
      " 'realistic 3d' 'realistic 3d models' 'reality' 'reality medicine'\n",
      " 'remains' 'remains open' 'remains open problem' 'resolution'\n",
      " 'resolution devices' 'revisions' 'skeleton' 'skeleton subspace'\n",
      " 'skeleton subspace deformation' 'skinning' 'skinning present' 'solution'\n",
      " 'solution animation' 'solution animation remains' 'ssd' 'ssd predominant'\n",
      " 'ssd predominant approach' 'subspace' 'subspace deformation'\n",
      " 'subspace deformation ssd' 'used' 'used fields'\n",
      " 'used fields entertainment' 'virtual' 'virtual reality'\n",
      " 'virtual reality medicine' 'widely' 'widely used' 'widely used fields']\n"
     ]
    }
   ],
   "source": [
    "# Test extracting n-grams from a small set of text\n",
    "sample_texts = df['Text'].head(5)  # First 5 rows for quick testing\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), stop_words='english')\n",
    "X_test = vectorizer.fit_transform(sample_texts)\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the required features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Argument lexicons\n",
    "agreement_lexicon = ['agree', 'yes', 'definitely', 'sure', 'absolutely', 'of course', , 'agreement', 'consistent', 'consistent with', 'support', 'supports', 'endorses']\n",
    "disagreement_lexicon = ['disagree', 'no', 'never', 'not', 'don’t', 'won’t', 'disagreement', 'opposes', 'opposed', 'against', 'contradicts]\n",
    "\n",
    "\n",
    "# Hedge words\n",
    "hedge_words = ['perhaps', 'maybe', 'possibly', 'could', 'might', 'probably', 'likely', 'uncertain', 'should']\n",
    "\n",
    "# Modal verbs list\n",
    "modal_verbs = ['can', 'could', 'may', 'might', 'shall', 'should', 'will', 'would']\n",
    "\n",
    "# Define a list of negation words\n",
    "negation_lexicon = ['not', 'never', 'no', 'none', 'nothing', 'neither']\n",
    "# Function to extract n-grams\n",
    "def extract_ngrams(text, ngram_range=(1, 3)):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    ngrams = vectorizer.fit_transform([text])\n",
    "    return vectorizer.get_feature_names_out()\n",
    "\n",
    "# Extract Argument Lexicons (Agreement and Disagreement)\n",
    "def extract_argument_lexicon_features(text):\n",
    "    agreement_count = sum([word in text.lower() for word in agreement_lexicon])\n",
    "    disagreement_count = sum([word in text.lower() for word in disagreement_lexicon])\n",
    "    return agreement_count, disagreement_count\n",
    "\n",
    "# Extract Hedge Features\n",
    "def extract_hedge_features(text):\n",
    "    hedge_count = sum([word in text.lower() for word in hedge_words])\n",
    "    return hedge_count\n",
    "\n",
    "# Extract Modal Verbs\n",
    "def extract_modal_verbs(text):\n",
    "    doc = nlp(text)\n",
    "    modal_count = sum([token.lemma_ in modal_verbs for token in doc])\n",
    "    return modal_count\n",
    "\n",
    "# Detect Negation\n",
    "def detect_negation(text):\n",
    "    negation_patterns = [r'\\b(not|no|never|don\\'t|won\\'t|isn\\'t|aren\\'t|can\\'t)\\b']\n",
    "    negation_count = sum([bool(re.search(pattern, text.lower())) for pattern in negation_patterns])\n",
    "    return negation_count\n",
    "\n",
    "# Function to extract all features for each text\n",
    "def extract_features(df):\n",
    "    all_ngrams = []\n",
    "    other_features = []\n",
    "    \n",
    "    for text in df['Text']:\n",
    "        # Extract n-grams\n",
    "        ngrams = extract_ngrams(text)\n",
    "        ngram_features = list(ngrams)  # Get the ngram features\n",
    "        \n",
    "        # Extract argument lexicons (agreement, disagreement)\n",
    "        agreement_count, disagreement_count = extract_argument_lexicon_features(text)\n",
    "\n",
    "        # Extract hedge features\n",
    "        hedge_count = extract_hedge_features(text)\n",
    "\n",
    "        # Extract modal verbs\n",
    "        modal_count = extract_modal_verbs(text)\n",
    "\n",
    "        # Extract negation features\n",
    "        negation_count = detect_negation(text)\n",
    "\n",
    "        # Combine all the features into one list\n",
    "        other_features.append([agreement_count, disagreement_count, hedge_count, modal_count, negation_count])\n",
    "\n",
    "        # Store the ngram features as a separate part of the feature matrix\n",
    "        all_ngrams.append(ngram_features)\n",
    "    \n",
    "    return all_ngrams, other_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "count    13592.000000\n",
      "mean        59.892216\n",
      "std         45.405939\n",
      "min          1.000000\n",
      "25%         22.000000\n",
      "50%         53.000000\n",
      "75%         86.000000\n",
      "max        359.000000\n",
      "Name: Text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Text'].isnull().sum())  # Check for any null values\n",
    "print(df['Text'].apply(len).describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows after filtering: 13454\n",
      "                                                Text             Label\n",
      "0  complicated 3D character models are widely use...  background_claim\n",
      "1  The range of breathtaking realistic 3D models ...  background_claim\n",
      "2         a production cannot afford major revisions  background_claim\n",
      "3  providing a flexible and efficient solution to...         own_claim\n",
      "4  Skeleton Subspace Deformation (SSD) is the pre...  background_claim\n",
      "Logistic Regression Accuracy: 42.93%\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "background_claim       0.00      0.00      0.00      1039\n",
      "            data       0.00      0.00      0.00      1265\n",
      "       own_claim       0.43      1.00      0.60      1733\n",
      "\n",
      "        accuracy                           0.43      4037\n",
      "       macro avg       0.14      0.33      0.20      4037\n",
      "    weighted avg       0.18      0.43      0.26      4037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import spacy\n",
    "\n",
    "\n",
    "# Extract the features\n",
    "X = extract_features(df)\n",
    "\n",
    "# Preparing the target labels (Y)\n",
    "y = df['Label'].values\n",
    "\n",
    "# Spliting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the labels on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Printing the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
