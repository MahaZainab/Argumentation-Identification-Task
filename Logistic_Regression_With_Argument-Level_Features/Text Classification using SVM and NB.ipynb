{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef6102",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 98\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_ngrams, other_features\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Step 4: Feature Extraction and Model Training\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Extract n-grams and other features\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m ngrams, other_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Create a CountVectorizer to extract features for all n-grams (unigrams, bigrams, trigrams)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))  \u001b[38;5;66;03m# Extract unigrams, bigrams, and trigrams\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 72\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     68\u001b[0m other_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Extract n-grams (Unigrams, Bigrams, Trigrams)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     ngrams \u001b[38;5;241m=\u001b[39m \u001b[43mextract_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     ngram_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ngrams)  \u001b[38;5;66;03m# Get the ngram features\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# Extract argument lexicons (agreement, disagreement)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m, in \u001b[0;36mextract_ngrams\u001b[1;34m(text, ngram_range)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_ngrams\u001b[39m(text, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)):\n\u001b[0;32m     31\u001b[0m     vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(ngram_range\u001b[38;5;241m=\u001b[39mngram_range)\n\u001b[1;32m---> 32\u001b[0m     ngrams \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Initialize spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text data\n",
    "data = {\n",
    "    'Text': [\n",
    "        \"I love this product, it works wonderfully!\", \n",
    "        \"This is absolutely the worst experience I’ve ever had.\",\n",
    "        \"Maybe this one will be better, I'm not sure.\",\n",
    "        \"I can't believe how good it is.\",\n",
    "        \"I don't think it's going to work.\"\n",
    "    ],\n",
    "    'Label': [1, 0, 1, 1, 0]  # Example labels (1: Positive, 0: Negative)\n",
    "}\n",
    "Corpus = pd.read_csv(\"compiled_output.csv\")\n",
    "Corpus.head()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# 1. **Extract N-grams (Unigrams, Bigrams, Trigrams)**\n",
    "def extract_ngrams(text, ngram_range=(1, 3)):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    ngrams = vectorizer.fit_transform([text])\n",
    "    return vectorizer.get_feature_names_out()\n",
    "\n",
    "# 2. **Argument Lexicons (Agreement and Disagreement)**\n",
    "agreement_lexicon = ['agree', 'yes', 'definitely', 'sure', 'absolutely', 'of course']\n",
    "disagreement_lexicon = ['disagree', 'no', 'never', 'not', 'don’t', 'won’t']\n",
    "\n",
    "def extract_argument_lexicon_features(text):\n",
    "    agreement_count = sum([word in text.lower() for word in agreement_lexicon])\n",
    "    disagreement_count = sum([word in text.lower() for word in disagreement_lexicon])\n",
    "    return agreement_count, disagreement_count\n",
    "\n",
    "# 3. **Extract Hedge Features**\n",
    "hedge_words = ['perhaps', 'maybe', 'possibly', 'could', 'might', 'probably']\n",
    "\n",
    "def extract_hedge_features(text):\n",
    "    hedge_count = sum([word in text.lower() for word in hedge_words])\n",
    "    return hedge_count\n",
    "\n",
    "# 4. **Extract Modal Verbs (Using spaCy)**\n",
    "def extract_modal_verbs(text):\n",
    "    doc = nlp(text)\n",
    "    modal_verbs = ['can', 'could', 'may', 'might', 'shall', 'should', 'will', 'would']\n",
    "    modal_count = sum([token.lemma_ in modal_verbs for token in doc])\n",
    "    return modal_count\n",
    "\n",
    "# 5. **Negation Detection (Using Regular Expressions)**\n",
    "def detect_negation(text):\n",
    "    negation_patterns = [r'\\b(not|no|never|don\\'t|won\\'t|isn\\'t|aren\\'t|can\\'t)\\b']\n",
    "    negation_count = sum([bool(re.search(pattern, text.lower())) for pattern in negation_patterns])\n",
    "    return negation_count\n",
    "\n",
    "# Step 3: Preprocess the Text and Extract Features\n",
    "\n",
    "def extract_features(df):\n",
    "    all_ngrams = []\n",
    "    other_features = []\n",
    "    \n",
    "    for text in df['Text']:\n",
    "        # Extract n-grams (Unigrams, Bigrams, Trigrams)\n",
    "        ngrams = extract_ngrams(text)\n",
    "        ngram_features = list(ngrams)  # Get the ngram features\n",
    "        \n",
    "        # Extract argument lexicons (agreement, disagreement)\n",
    "        agreement_count, disagreement_count = extract_argument_lexicon_features(text)\n",
    "\n",
    "        # Extract hedge features\n",
    "        hedge_count = extract_hedge_features(text)\n",
    "\n",
    "        # Extract modal verbs\n",
    "        modal_count = extract_modal_verbs(text)\n",
    "\n",
    "        # Extract negation features\n",
    "        negation_count = detect_negation(text)\n",
    "\n",
    "        # Combine all the features into one list\n",
    "        other_features.append([agreement_count, disagreement_count, hedge_count, modal_count, negation_count])\n",
    "\n",
    "        # Store the ngram features as a separate part of the feature matrix\n",
    "        all_ngrams.append(ngram_features)\n",
    "    \n",
    "    return all_ngrams, other_features\n",
    "\n",
    "# Step 4: Feature Extraction and Model Training\n",
    "\n",
    "# Extract n-grams and other features\n",
    "ngrams, other_features = extract_features(df)\n",
    "\n",
    "# Create a CountVectorizer to extract features for all n-grams (unigrams, bigrams, trigrams)\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))  # Extract unigrams, bigrams, and trigrams\n",
    "X_ngrams = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Now, we need to combine the n-gram features and other features\n",
    "import numpy as np\n",
    "\n",
    "# Convert the n-grams matrix to a dense array and concatenate with other features\n",
    "X_ngrams_dense = X_ngrams.toarray()\n",
    "X_combined = np.hstack([X_ngrams_dense, np.array(other_features)])\n",
    "\n",
    "# Convert labels to a numpy array\n",
    "y = df['Label'].values\n",
    "\n",
    "# Check class distribution before the split\n",
    "print(\"Class distribution in the dataset:\")\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "# Stratified split ensures that the distribution of classes is maintained in both the train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Convert numpy arrays to pandas Series to use value_counts\n",
    "y_train_series = pd.Series(y_train)\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Check class distribution after the split\n",
    "print(\"Class distribution in the training set:\")\n",
    "print(y_train_series.value_counts())\n",
    "\n",
    "print(\"Class distribution in the test set:\")\n",
    "print(y_test_series.value_counts())\n",
    "\n",
    "# 5. **Train Logistic Regression Model**\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')  # Optional: Use class weights if data is imbalanced\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 6. **Make Predictions and Evaluate**\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a01c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0458b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0733a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complicated 3D character models are widely use...</td>\n",
       "      <td>background_claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The range of breathtaking realistic 3D models ...</td>\n",
       "      <td>background_claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a production cannot afford major revisions</td>\n",
       "      <td>background_claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>providing a flexible and efficient solution to...</td>\n",
       "      <td>own_claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skeleton Subspace Deformation (SSD) is the pre...</td>\n",
       "      <td>background_claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text             Label\n",
       "0  complicated 3D character models are widely use...  background_claim\n",
       "1  The range of breathtaking realistic 3D models ...  background_claim\n",
       "2         a production cannot afford major revisions  background_claim\n",
       "3  providing a flexible and efficient solution to...         own_claim\n",
       "4  Skeleton Subspace Deformation (SSD) is the pre...  background_claim"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = pd.read_csv(\"compiled_output.csv\")\n",
    "Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cfa8b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13592"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce02aa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13592, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f98e59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     False\n",
       "Label    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7835ef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>One solution is to use Baumgarte stabilization</td>\n",
       "      <td>own_claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8086</th>\n",
       "      <td>The problem left here</td>\n",
       "      <td>background_claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>In practice this has been considered the major...</td>\n",
       "      <td>background_claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11944</th>\n",
       "      <td>a multitude of different cloth models have eme...</td>\n",
       "      <td>background_claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10729</th>\n",
       "      <td>16</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text             Label\n",
       "13300     One solution is to use Baumgarte stabilization         own_claim\n",
       "8086                               The problem left here  background_claim\n",
       "2669   In practice this has been considered the major...  background_claim\n",
       "11944  a multitude of different cloth models have eme...  background_claim\n",
       "10729                                                 16              data"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991ad7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e41fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'countplot')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(Corpus.Label)\n",
    "plt.xlabel(\"Label\")\n",
    "plt.title(\"countplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ea0c150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_rus.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker_tab.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\maxent_treebank_pos_tagger_tab.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping help\\tagsets.zip.\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping help\\tagsets_json.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f54799ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [complicated, 3d, character, models, are, wide...\n",
      "1    [the, range, of, breathtaking, realistic, 3d, ...\n",
      "2    [a, production, can, not, afford, major, revis...\n",
      "3    [providing, a, flexible, and, efficient, solut...\n",
      "4    [skeleton, subspace, deformation, (, ssd, ), i...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Assuming Corpus is a pandas DataFrame\n",
    "Corpus['Text'] = [entry.lower() for entry in Corpus['Text']]\n",
    "\n",
    "# Tokenization\n",
    "Corpus['Text'] = [word_tokenize(entry) for entry in Corpus['Text']]\n",
    "\n",
    "# Display the first few tokenized entries\n",
    "print(Corpus['Text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edfd7511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_original</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[complicated, 3d, character, models, are, wide...</td>\n",
       "      <td>background_claim</td>\n",
       "      <td>[complicated, 3d, character, models, are, wide...</td>\n",
       "      <td>complicated 3d character models are widely use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, range, of, breathtaking, realistic, 3d, ...</td>\n",
       "      <td>background_claim</td>\n",
       "      <td>[the, range, of, breathtaking, realistic, 3d, ...</td>\n",
       "      <td>the range of breathtaking realistic 3d models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, production, can, not, afford, major, revis...</td>\n",
       "      <td>background_claim</td>\n",
       "      <td>[a, production, can, not, afford, major, revis...</td>\n",
       "      <td>a production cannot afford major revisions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[providing, a, flexible, and, efficient, solut...</td>\n",
       "      <td>own_claim</td>\n",
       "      <td>[providing, a, flexible, and, efficient, solut...</td>\n",
       "      <td>providing a flexible and efficient solution to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[skeleton, subspace, deformation, (, ssd, ), i...</td>\n",
       "      <td>background_claim</td>\n",
       "      <td>[skeleton, subspace, deformation, (, ssd, ), i...</td>\n",
       "      <td>skeleton subspace deformation (ssd) is the pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text             Label  \\\n",
       "0  [complicated, 3d, character, models, are, wide...  background_claim   \n",
       "1  [the, range, of, breathtaking, realistic, 3d, ...  background_claim   \n",
       "2  [a, production, can, not, afford, major, revis...  background_claim   \n",
       "3  [providing, a, flexible, and, efficient, solut...         own_claim   \n",
       "4  [skeleton, subspace, deformation, (, ssd, ), i...  background_claim   \n",
       "\n",
       "                                       text_original  \\\n",
       "0  [complicated, 3d, character, models, are, wide...   \n",
       "1  [the, range, of, breathtaking, realistic, 3d, ...   \n",
       "2  [a, production, can, not, afford, major, revis...   \n",
       "3  [providing, a, flexible, and, efficient, solut...   \n",
       "4  [skeleton, subspace, deformation, (, ssd, ), i...   \n",
       "\n",
       "                                                text  \n",
       "0  complicated 3d character models are widely use...  \n",
       "1  the range of breathtaking realistic 3d models ...  \n",
       "2         a production cannot afford major revisions  \n",
       "3  providing a flexible and efficient solution to...  \n",
       "4  skeleton subspace deformation (ssd) is the pre...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Removing Blank Spaces\n",
    "Corpus['Text'].dropna(inplace=True)\n",
    "# 2. Changing all text to lowercase\n",
    "Corpus['text_original'] = Corpus['Text']\n",
    "Corpus['Text'] = [\n",
    "    [word.lower() for word in entry] if isinstance(entry, list) else entry.lower()\n",
    "    for entry in Corpus['Text']\n",
    "]\n",
    "#Corpus['Text'] = [entry.lower() for entry in Corpus['Text']]\n",
    "# 3. Tokenization-In this each entry in the corpus will be broken into set of words\n",
    "Corpus['Text'] = [\n",
    "    [word.lower() for word in entry] if isinstance(entry, list) else entry.lower()  # Lowercase each word in list\n",
    "    for entry in Corpus['Text']\n",
    "]\n",
    "#Corpus['Text']= [word_tokenize(entry) for entry in Corpus['Text']]\n",
    "# 4. Remove Stop words, Non-Numeric and perfoming Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b28f16e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,entry in enumerate(Corpus['Text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea98076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus.drop(['text'], axis=1)\n",
    "output_path = 'preprocessed_data.csv'\n",
    "Corpus.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca1f43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['Label'],test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63d389ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2487a8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'complicate': np.int64(493), 'character': np.int64(404), 'model': np.int64(1694), 'widely': np.int64(2945), 'use': np.int64(2842), 'field': np.int64(1004), 'entertainment': np.int64(877), 'virtual': np.int64(2891), 'reality': np.int64(2141), 'range': np.int64(2118), 'realistic': np.int64(2139), 'limit': np.int64(1529), 'artist': np.int64(174), 'resolution': np.int64(2239), 'device': np.int64(715), 'production': np.int64(2046), 'afford': np.int64(76), 'major': np.int64(1589), 'provide': np.int64(2072), 'flexible': np.int64(1031), 'efficient': np.int64(824), 'solution': np.int64(2479), 'animation': np.int64(127), 'remain': np.int64(2205), 'open': np.int64(1826), 'problem': np.int64(2035), 'skeleton': np.int64(2451), 'subspace': np.int64(2584), 'deformation': np.int64(664), 'ssd': np.int64(2524), 'approach': np.int64(147), 'skin': np.int64(2454), 'present': np.int64(2013), 'drive': np.int64(795), 'natural': np.int64(1740), 'believable': np.int64(266), 'manner': np.int64(1600), 'trivial': np.int64(2754), 'ease': np.int64(810), 'implementation': np.int64(1237), 'low': np.int64(1575), 'cost': np.int64(600), 'compute': np.int64(510), 'game': np.int64(1084), 'realtime': np.int64(2143), 'application': np.int64(144), 'edit': np.int64(816), 'geometry': np.int64(1108), 'rest': np.int64(2249), 'pose': np.int64(1971), 'commonly': np.int64(474), 'apply': np.int64(146), 'influence': np.int64(1308), 'also': np.int64(97), 'notorious': np.int64(1791), 'artifact': np.int64(171), 'rotate': np.int64(2295), 'elbow': np.int64(842), 'extreme': np.int64(972), 'example': np.int64(920), 'base': np.int64(248), 'method': np.int64(1661), 'space': np.int64(2490), 'psd': np.int64(2078), 'candidate': np.int64(360), 'correct': np.int64(591), 'limitation': np.int64(1530), 'may': np.int64(1631), 'compensation': np.int64(485), 'underlie': np.int64(2791), 'animator': np.int64(128), 'specify': np.int64(2504), 'perform': np.int64(1911), 'best': np.int64(276), 'interpolate': np.int64(1365), 'action': np.int64(31), 'must': np.int64(1734), 'inverted': np.int64(1389), 'order': np.int64(1838), 'push': np.int64(2089), 'operation': np.int64(1828), 'representative': np.int64(2223), 'family': np.int64(987), 'basic': np.int64(249), 'skinning': np.int64(2455), 'inverse': np.int64(1387), 'strategy': np.int64(2556), 'good': np.int64(1120), 'performance': np.int64(1912), 'framework': np.int64(1063), 'without': np.int64(2955), 'improve': np.int64(1251), 'quality': np.int64(2097), 'interactive': np.int64(1351), 'high': np.int64(1176), 'algorithm': np.int64(85), 'category': np.int64(381), 'generate': np.int64(1099), 'effect': np.int64(818), 'compare': np.int64(480), 'geometric': np.int64(1105), 'counterpart': np.int64(603), 'combine': np.int64(469), 'shape': np.int64(2393), 'blending': np.int64(295), 'formulate': np.int64(1052), 'scatter': np.int64(2331), 'data': np.int64(642), 'interpolation': np.int64(1367), 'sculpt': np.int64(2345), 'otherwise': np.int64(1849), 'obtain': np.int64(1808), 'relate': np.int64(2192), 'research': np.int64(2233), 'effort': np.int64(826), 'speed': np.int64(2508), 'power': np.int64(1987), 'incorporate': np.int64(1267), 'linear': np.int64(1537), 'element': np.int64(845), 'rbf': np.int64(2129), 'produce': np.int64(2044), 'constant': np.int64(543), 'change': np.int64(403), 'principal': np.int64(2025), 'component': np.int64(495), 'individual': np.int64(1289), 'kinematic': np.int64(1449), 'joint': np.int64(1423), 'instead': np.int64(1336), 'store': np.int64(2552), 'displacement': np.int64(761), 'key': np.int64(1441), 'enable': np.int64(859), 'render': np.int64(2212), 'large': np.int64(1479), 'nonlinear': np.int64(1776), 'finite': np.int64(1020), 'human': np.int64(1197), 'hand': np.int64(1153), 'introduce': np.int64(1379), 'weight': np.int64(2933), 'deform': np.int64(662), 'consider': np.int64(535), 'identifies': np.int64(1212), 'statistically': np.int64(2540), 'relevant': np.int64(2200), 'bone': np.int64(304), 'approximate': np.int64(150), 'transforms': np.int64(2738), 'mesh': np.int64(1655), 'see': np.int64(2356), 'development': np.int64(712), 'recent': np.int64(2151), 'year': np.int64(2982), 'common': np.int64(473), 'practice': np.int64(1993), 'free': np.int64(1064), 'form': np.int64(1050), 'lattice': np.int64(1486), 'nurbs': np.int64(1799), 'curve': np.int64(628), 'result': np.int64(2255), 'require': np.int64(2229), 'implement': np.int64(1236), 'commercial': np.int64(472), 'package': np.int64(1862), 'simplicity': np.int64(2427), 'efficiency': np.int64(823), 'popular': np.int64(1967), 'circumstance': np.int64(422), 'animate': np.int64(125), 'number': np.int64(1795), 'real': np.int64(2137), 'time': np.int64(2697), 'vertex': np.int64(2879), 'transformation': np.int64(2736), 'easily': np.int64(811), 'graphic': np.int64(1130), 'card': np.int64(369), 'domain': np.int64(781), 'adjust': np.int64(61), 'one': np.int64(1823), 'way': np.int64(2927), 'strictly': np.int64(2562), 'transform': np.int64(2735), 'go': np.int64(1117), 'wrong': np.int64(2977), 'synthesize': np.int64(2633), 'many': np.int64(1603), 'part': np.int64(1880), 'involve': np.int64(1394), 'structure': np.int64(2567), 'combination': np.int64(468), 'blend': np.int64(294), 'nice': np.int64(1768), 'mention': np.int64(1649), 'scheme': np.int64(2336), 'discuss': np.int64(756), 'publication': np.int64(2080), 'reason': np.int64(2146), 'still': np.int64(2547), 'ambiguous': np.int64(105), 'invert': np.int64(1388), 'right': np.int64(2276), 'choice': np.int64(415), 'improvement': np.int64(1253), 'simply': np.int64(2431), 'matrix': np.int64(1625), 'superior': np.int64(2609), 'take': np.int64(2639), 'original': np.int64(1842), 'th': np.int64(2676), 'simplify': np.int64(2430), 'rotation': np.int64(2296), 'ignore': np.int64(1216), 'issue': np.int64(1402), 'accumulate': np.int64(17), 'first': np.int64(1021), 'second': np.int64(2353), 'forward': np.int64(1055), 'case': np.int64(379), 'direction': np.int64(738), 'deformed': np.int64(665), 'always': np.int64(103), 'keep': np.int64(1439), 'cylinder': np.int64(635), 'figure': np.int64(1006), 'along': np.int64(95), 'suppose': np.int64(2615), 'local': np.int64(1555), 'correction': np.int64(592), 'extend': np.int64(959), 'whole': np.int64(2942), 'object': np.int64(1801), 'matter': np.int64(1626), 'experience': np.int64(944), 'amount': np.int64(109), 'unnecessary': np.int64(2816), 'work': np.int64(2960), 'building': np.int64(337), 'distance': np.int64(766), 'different': np.int64(722), 'adopt': np.int64(64), 'another': np.int64(134), 'specific': np.int64(2500), 'advantage': np.int64(68), 'powell': np.int64(1986), 'need': np.int64(1751), 'explicit': np.int64(948), 'computation': np.int64(507), 'function': np.int64(1076), 'gradient': np.int64(1127), 'suitable': np.int64(2603), 'treat': np.int64(2745), 'black': np.int64(293), 'box': np.int64(313), 'available': np.int64(217), 'repeat': np.int64(2216), 'cycle': np.int64(633), 'line': np.int64(1536), 'minimization': np.int64(1678), 'conjugate': np.int64(525), 'optimization': np.int64(1833), 'due': np.int64(802), 'course': np.int64(606), 'converge': np.int64(575), 'minimum': np.int64(1680), 'equation': np.int64(889), 'singular': np.int64(2442), 'type': np.int64(2776), 'possible': np.int64(1978), 'desired': np.int64(701), 'lie': np.int64(1519), 'null': np.int64(1794), 'rare': np.int64(2122), 'handle': np.int64(1155), 'small': np.int64(2467), 'rearrangement': np.int64(2145), 'equal': np.int64(887), 'two': np.int64(2775), 'frame': np.int64(1062), 'unrealistic': np.int64(2821), 'generally': np.int64(1098), 'zero': np.int64(2991), 'minimize': np.int64(1679), 'well': np.int64(2937), 'consistent': np.int64(541), 'linearly': np.int64(1539), 'proportional': np.int64(2064), 'simplified': np.int64(2429), 'information': np.int64(1310), 'process': np.int64(2041), 'critical': np.int64(615), 'setup': np.int64(2386), 'insignificant': np.int64(1326), 'physical': np.int64(1930), 'principle': np.int64(2026), 'detailed': np.int64(706), 'playback': np.int64(1952), 'become': np.int64(257), 'quite': np.int64(2108), 'heavy': np.int64(1164), 'visual': np.int64(2898), 'fidelity': np.int64(1003), 'serve': np.int64(2380), 'smoothly': np.int64(2471), 'visually': np.int64(2901), 'attractive': np.int64(203), 'rigid': np.int64(2277), 'modelling': np.int64(1696), 'simulation': np.int64(2434), 'simpler': np.int64(2426), 'parametric': np.int64(1877), 'prototype': np.int64(2069), 'fixed': np.int64(1027), 'parameter': np.int64(1874), 'propose': np.int64(2065), 'unified': np.int64(2801), 'allow': np.int64(91), 'proprietary': np.int64(2066), 'operator': np.int64(1829), 'define': np.int64(659), 'surface': np.int64(2616), 'deforms': np.int64(668), 'follow': np.int64(1043), 'movement': np.int64(1718), 'underlying': np.int64(2792), 'relation': np.int64(2194), 'control': np.int64(569), 'point': np.int64(1957), 'list': np.int64(1545), 'indicate': np.int64(1283), 'position': np.int64(1973), 'animated': np.int64(126), 'weighted': np.int64(2934), 'associate': np.int64(182), 'collapse': np.int64(458), 'delta': np.int64(675), 'correspond': np.int64(596), 'help': np.int64(1166), 'task': np.int64(2646), 'solve': np.int64(2480), 'angle': np.int64(122), 'depend': np.int64(681), 'value': np.int64(2856), 'tan': np.int64(2641), 'describe': np.int64(692), 'shoulder': np.int64(2409), 'knee': np.int64(1455), 'neck': np.int64(1750), 'would': np.int64(2968), 'necessitate': np.int64(1749), 'support': np.int64(2614), 'replace': np.int64(2218), 'general': np.int64(1093), 'find': np.int64(1015), 'give': np.int64(1113), 'radial': np.int64(2110), 'basis': np.int64(250), 'particular': np.int64(1885), 'actually': np.int64(39), 'variable': np.int64(2862), 'idea': np.int64(1208), 'try': np.int64(2761), 'stop': np.int64(2549), 'decrease': np.int64(654), 'choose': np.int64(416), 'next': np.int64(1767), 'main': np.int64(1586), 'concern': np.int64(517), 'maya': np.int64(1632), 'tweak': np.int64(2770), 'procedure': np.int64(2039), 'add': np.int64(50), 'system': np.int64(2636), 'divide': np.int64(777), 'phase': np.int64(1926), 'minimal': np.int64(1676), 'code': np.int64(451), 'final': np.int64(1013), 'synthesis': np.int64(2632), 'much': np.int64(1721), 'poorly': np.int64(1965), 'potentially': np.int64(1985), 'extra': np.int64(966), 'review': np.int64(2266), 'deformable': np.int64(663), 'compromise': np.int64(506), 'complexity': np.int64(492), 'aspect': np.int64(176), 'important': np.int64(1243), 'necessary': np.int64(1748), 'design': np.int64(697), 'exist': np.int64(935), 'literature': np.int64(1546), 'differ': np.int64(720), 'intended': np.int64(1346), 'area': np.int64(157), 'generality': np.int64(1094), 'know': np.int64(1456), 'skeletal': np.int64(2450), 'simple': np.int64(2425), 'versatile': np.int64(2877), 'consist': np.int64(539), 'segment': np.int64(2360), 'connect': np.int64(526), 'interpret': np.int64(1369), 'tree': np.int64(2747), 'whose': np.int64(2943), 'node': np.int64(1772), 'identify': np.int64(1213), 'edge': np.int64(815), 'polygonal': np.int64(1961), 'usually': np.int64(2847), 'equip': np.int64(891), 'normal': np.int64(1779), 'texture': np.int64(2673), 'humanoid': np.int64(1198), 'modeling': np.int64(1695), 'wide': np.int64(2944), 'soft': np.int64(2474), 'imaginary': np.int64(1228), 'cartoon': np.int64(378), 'creature': np.int64(613), 'plant': np.int64(1945), 'apparent': np.int64(138), 'complex': np.int64(491), 'rely': np.int64(2204), 'anatomy': np.int64(119), 'considerably': np.int64(537), 'individually': np.int64(1290), 'sufficient': np.int64(2599), 'manipulate': np.int64(1597), 'automatically': np.int64(213), 'exactly': np.int64(918), 'posture': np.int64(1983), 'propagate': np.int64(2057), 'standard': np.int64(2535), 'majority': np.int64(1590), 'come': np.int64(471), 'name': np.int64(1738), 'lb': np.int64(1490), 'envelop': np.int64(882), 'fast': np.int64(990), 'advantageous': np.int64(69), 'hardware': np.int64(1159), 'suffer': np.int64(2597), 'inherent': np.int64(1313), 'twist': np.int64(2773), 'lbs': np.int64(1491), 'volume': np.int64(2908), 'increase': np.int64(1270), 'early': np.int64(809), 'contribution': np.int64(568), 'et': np.int64(901), 'al': np.int64(82), 'numerous': np.int64(1798), 'computer': np.int64(512), 'often': np.int64(1819), 'unpublished': np.int64(2820), 'community': np.int64(475), 'lander': np.int64(1474), 'discover': np.int64(749), 'weber': np.int64(2931), 'addition': np.int64(52), 'auxiliary': np.int64(215), 'reduce': np.int64(2168), 'relationship': np.int64(2195), 'location': np.int64(1560), 'additional': np.int64(53), 'questionable': np.int64(2104), 'augmented': np.int64(206), 'article': np.int64(167), 'lewis': np.int64(1515), 'similar': np.int64(2422), 'sloan': np.int64(2465), 'kry': np.int64(1462), 'latter': np.int64(1485), 'analysis': np.int64(113), 'memory': np.int64(1648), 'requirement': np.int64(2231), 'capture': np.int64(367), 'drawback': np.int64(792), 'acquire': np.int64(25), 'include': np.int64(1260), 'like': np.int64(1525), 'muscle': np.int64(1730), 'bulging': np.int64(339), 'interesting': np.int64(1356), 'generalization': np.int64(1095), 'call': np.int64(358), 'enveloping': np.int64(883), 'wang': np.int64(2921), 'phillips': np.int64(1928), 'great': np.int64(1134), 'flexibility': np.int64(1030), 'disadvantage': np.int64(742), 'obvious': np.int64(1809), 'manually': np.int64(1602), 'multiweight': np.int64(1729), 'tool': np.int64(2707), 'mohr': np.int64(1705), 'interest': np.int64(1354), 'theoretical': np.int64(2679), 'view': np.int64(2887), 'explore': np.int64(952), 'medial': np.int64(1642), 'bloomenthal': np.int64(299), 'spherical': np.int64(2512), 'sb': np.int64(2325), 'kavan': np.int64(1435), 'zára': np.int64(2997), 'attach': np.int64(192), 'special': np.int64(2499), 'remove': np.int64(2211), 'gleicher': np.int64(1114), 'seem': np.int64(2359), 'sbs': np.int64(2326), 'mathematical': np.int64(1622), 'alexa': np.int64(84), 'slow': np.int64(2466), 'rather': np.int64(2125), 'none': np.int64(1775), 'cause': np.int64(382), 'straightforward': np.int64(2554), 'induce': np.int64(1291), 'nature': np.int64(1742), 'suggest': np.int64(2601), 'quaternion': np.int64(2101), 'representation': np.int64(2222), 'translation': np.int64(2741), 'center': np.int64(388), 'cope': np.int64(584), 'determination': np.int64(709), 'multiple': np.int64(1724), 'get': np.int64(1110), 'hard': np.int64(1158), 'shoemake': np.int64(2406), 'bus': np.int64(350), 'fillmore': np.int64(1009), 'park': np.int64(1879), 'average': np.int64(219), 'previous': np.int64(2019), 'enough': np.int64(872), 'purpose': np.int64(2087), 'appropriate': np.int64(148), 'probably': np.int64(2034), 'others': np.int64(1848), 'plausible': np.int64(1950), 'resolve': np.int64(2240), 'input': np.int64(1322), 'program': np.int64(2047), 'even': np.int64(907), 'carefully': np.int64(372), 'tune': np.int64(2763), 'alternative': np.int64(101), 'demand': np.int64(676), 'sensitive': np.int64(2368), 'body': np.int64(302), 'algorithms': np.int64(87), 'row': np.int64(2302), 'surprisingly': np.int64(2619), 'tend': np.int64(2659), 'unlikely': np.int64(2812), 'left': np.int64(1504), 'wrist': np.int64(2975), 'negligible': np.int64(1753), 'set': np.int64(2382), 'dominate': np.int64(782), 'cache': np.int64(353), 'computed': np.int64(511), 'difference': np.int64(721), 'barely': np.int64(245), 'observable': np.int64(1803), 'section': np.int64(2355), 'substantial': np.int64(2585), 'qlerp': np.int64(2091), 'behaves': np.int64(262), 'slerp': np.int64(2459), 'contrast': np.int64(566), 'decomposition': np.int64(653), 'table': np.int64(2638), 'theoretically': np.int64(2680), 'could': np.int64(602), 'mean': np.int64(1633), 'perfect': np.int64(1909), 'compete': np.int64(486), 'layered': np.int64(1489), 'offer': np.int64(1816), 'reasonable': np.int64(2147), 'price': np.int64(2021), 'elimination': np.int64(848), 'overhead': np.int64(1858), 'internal': np.int64(1361), 'especially': np.int64(895), 'situation': np.int64(2446), 'somewhat': np.int64(2485), 'estimate': np.int64(899), 'do': np.int64(778), 'cover': np.int64(607), 'reference': np.int64(2175), 'da': np.int64(636), 'yet': np.int64(2983), 'orientation': np.int64(1841), 'actual': np.int64(38), 'coordinate': np.int64(582), 'align': np.int64(88), 'world': np.int64(2963), 'following': np.int64(1045), 'return': np.int64(2263), 'current': np.int64(625), 'occur': np.int64(1812), 'together': np.int64(2704), 'complete': np.int64(489), 'old': np.int64(1820), 'smooth': np.int64(2469), 'allows': np.int64(92), 'assignment': np.int64(180), 'circular': np.int64(420), 'arc': np.int64(155), 'extremal': np.int64(971), 'degree': np.int64(672), 'single': np.int64(2441), 'understand': np.int64(2794), 'undesirable': np.int64(2796), 'formula': np.int64(1051), 'less': np.int64(1510), 'vector': np.int64(2873), 'valuable': np.int64(2855), 'insight': np.int64(1325), 'preserve': np.int64(2015), 'orthogonality': np.int64(1846), 'rotational': np.int64(2297), 'rank': np.int64(2119), 'interpolated': np.int64(1366), 'happen': np.int64(1157), 'defect': np.int64(657), 'visible': np.int64(2896), 'proximity': np.int64(2075), 'configuration': np.int64(520), 'regular': np.int64(2188), 'scaling': np.int64(2329), 'responsible': np.int64(2248), 'loss': np.int64(1573), 'establish': np.int64(898), 'success': np.int64(2592), 'represent': np.int64(2220), 'convenient': np.int64(573), 'really': np.int64(2142), 'column': np.int64(467), 'pair': np.int64(1866), 'equivalent': np.int64(892), 'serious': np.int64(2379), 'difficulty': np.int64(728), 'transformed': np.int64(2737), 'every': np.int64(910), 'drift': np.int64(794), 'condition': np.int64(518), 'satisfy': np.int64(2323), 'influencing': np.int64(1309), 'inevitable': np.int64(1299), 'relative': np.int64(2196), 'chain': np.int64(399), 'avoid': np.int64(221), 'identity': np.int64(1214), 'associated': np.int64(183), 'close': np.int64(437), 'assign': np.int64(179), 'lt': np.int64(1577), 'make': np.int64(1591), 'assumption': np.int64(186), 'vary': np.int64(2870), 'norm': np.int64(1778), 'routine': np.int64(2301), 'per': np.int64(1905), 'anderson': np.int64(120), 'encounter': np.int64(862), 'neighboring': np.int64(1756), 'determine': np.int64(710), 'precisely': np.int64(1997), 'beginning': np.int64(260), 'omit': np.int64(1821), 'svd': np.int64(2622), 'therefore': np.int64(2683), 'run': np.int64(2307), 'several': np.int64(2388), 'ten': np.int64(2658), 'already': np.int64(96), 'receive': np.int64(2150), 'attention': np.int64(199), 'substantially': np.int64(2586), 'goal': np.int64(1118), 'comparable': np.int64(478), 'correspondence': np.int64(597), 'unique': np.int64(2805), 'unit': np.int64(2807), 'assumes': np.int64(185), 'product': np.int64(2045), 'short': np.int64(2407), 'project': np.int64(2052), 'uniform': np.int64(2802), 'gt': np.int64(1144), 'concatenate': np.int64(513), 'multiply': np.int64(1727), 'express': np.int64(956), 'pr': np.int64(1990), 'pp': np.int64(1989), 'write': np.int64(2976), 'axis': np.int64(225), 'independent': np.int64(1280), 'fix': np.int64(1026), 'radian': np.int64(2111), 'upper': np.int64(2832), 'bound': np.int64(310), 'practical': np.int64(1991), 'big': np.int64(281), 'generalize': np.int64(1096), 'assume': np.int64(184), 'exceed': np.int64(921), 'end': np.int64(863), 'certain': np.int64(393), 'co': np.int64(447), 'sin': np.int64(2438), 'substitute': np.int64(2587), 'analogy': np.int64(112), 'subsequently': np.int64(2582), 'normalize': np.int64(1781), 'shift': np.int64(2402), 'manifest': np.int64(1595), 'evaluate': np.int64(905), 'similarly': np.int64(2424), 'execute': np.int64(932), 'expression': np.int64(957), 'multiplication': np.int64(1725), 'convert': np.int64(577), 'save': np.int64(2324), 'place': np.int64(1939), 'indeed': np.int64(1276), 'nothing': np.int64(1787), 'arbitrary': np.int64(154), 'rot': np.int64(2294), 'easy': np.int64(812), 'creation': np.int64(611), 'accessible': np.int64(10), 'novice': np.int64(1793), 'child': np.int64(413), 'http': np.int64(1195), 'igarashi': np.int64(1215), 'bring': np.int64(325), 'static': np.int64(2538), 'life': np.int64(1520), 'user': np.int64(2844), 'rig': np.int64(2274), 'conventional': np.int64(574), 'inside': np.int64(1324), 'tedium': np.int64(2651), 'difficult': np.int64(727), 'eliminate': np.int64(847), 'researcher': np.int64(2234), 'able': np.int64(2), 'unicorn': np.int64(2800), 'quadruped': np.int64(2096), 'button': np.int64(351), 'start': np.int64(2536), 'motion': np.int64(1712), 'output': np.int64(1853), 'move': np.int64(1717), 'miss': np.int64(1685), 'portion': np.int64(1970), 'rigging': np.int64(2275), 'transfer': np.int64(2734), 'address': np.int64(55), 'prior': np.int64(2029), 'step': np.int64(2541), 'embed': np.int64(849), 'attachment': np.int64(194), 'biped': np.int64(289), 'anatomically': np.int64(118), 'robot': np.int64(2284), 'something': np.int64(2483), 'little': np.int64(1547), 'challenge': np.int64(401), 'construct': np.int64(548), 'penalty': np.int64(1901), 'penalize': np.int64(1900), 'embeddings': np.int64(852), 'new': np.int64(1764), 'learn': np.int64(1497), 'test': np.int64(2667), 'placement': np.int64(1940), 'hint': np.int64(1180), 'boundary': np.int64(311), 'approximately': np.int64(151), 'proportion': np.int64(2063), 'roughly': np.int64(2300), 'technique': np.int64(2648), 'automatic': np.int64(212), 'heuristic': np.int64(1172), 'accelerate': np.int64(5), 'search': np.int64(2351), 'optimal': np.int64(1832), 'exponential': np.int64(953), 'laplace': np.int64(1477), 'diffusion': np.int64(730), 'useful': np.int64(2843), 'online': np.int64(1824), 'retargetting': np.int64(2262), 'constrain': np.int64(545), 'foot': np.int64(1046), 'trajectory': np.int64(2733), 'choi': np.int64(414), 'ko': np.int64(1458), 'focus': np.int64(1040), 'target': np.int64(2645), 'exception': np.int64(924), 'spatial': np.int64(2497), 'keyframing': np.int64(1445), 'manipulation': np.int64(1598), 'definition': np.int64(661), 'articulation': np.int64(170), 'relies': np.int64(2203), 'strong': np.int64(2564), 'ability': np.int64(1), 'infer': np.int64(1303), 'expect': np.int64(939), 'articulated': np.int64(169), 'constraint': np.int64(547), 'extraction': np.int64(968), 'embedding': np.int64(851), 'extract': np.int64(967), 'voronoi': np.int64(2912), 'assistance': np.int64(181), 'repulsive': np.int64(2227), 'force': np.int64(1048), 'liu': np.int64(1548), 'katz': np.int64(1434), 'partition': np.int64(1887), 'wade': np.int64(2917), 'discontinuity': np.int64(746), 'likely': np.int64(1527), 'topology': np.int64(2713), 'generation': np.int64(1102), 'fitting': np.int64(1023), 'template': np.int64(2653), 'overall': np.int64(1855), 'mistake': np.int64(1687), 'arm': np.int64(163), 'expected': np.int64(940), 'leg': np.int64(1505), 'fairly': np.int64(983), 'fit': np.int64(1022), 'successful': np.int64(2593), 'volumetric': np.int64(2909), 'almost': np.int64(93), 'adapt': np.int64(44), 'lipman': np.int64(1543), 'yu': np.int64(2987), 'unsuitable': np.int64(2827), 'size': np.int64(2448), 'shortcoming': np.int64(2408), 'gpu': np.int64(1124), 'mode': np.int64(1693), 'sufficiently': np.int64(2600), 'either': np.int64(835), 'dependent': np.int64(684), 'default': np.int64(656), 'autodesk': np.int64(209), 'solely': np.int64(2477), 'intersect': np.int64(1371), 'diagram': np.int64(718), 'face': np.int64(976), 'hip': np.int64(1181), 'region': np.int64(2186), 'nicely': np.int64(1769), 'look': np.int64(1567), 'complicated': np.int64(494), 'objective': np.int64(1802), 'directly': np.int64(739), 'continuous': np.int64(560), 'pinocchio': np.int64(1936), 'graph': np.int64(1129), 'potential': np.int64(1984), 'path': np.int64(1894), 'within': np.int64(2954), 'respect': np.int64(2243), 'discrete': np.int64(751), 'attribute': np.int64(204), 'cube': np.int64(620), 'tolerance': np.int64(2705), 'adaptively': np.int64(48), 'sample': np.int64(2316), 'sign': np.int64(2414), 'octree': np.int64(1814), 'frisken': np.int64(1072), 'exact': np.int64(917), 'accuracy': np.int64(19), 'negative': np.int64(1752), 'split': np.int64(2518), 'cell': np.int64(387), 'guarantee': np.int64(1145), 'interior': np.int64(1358), 'adaptive': np.int64(47), 'traverse': np.int64(2744), 'grid': np.int64(1136), 'impose': np.int64(1245), 'want': np.int64(2922), 'noisy': np.int64(1774), 'filter': np.int64(1011), 'sampled': np.int64(2317), 'sort': np.int64(2487), 'outside': np.int64(1854), 'previously': np.int64(2020), 'sphere': np.int64(2511), 'radius': np.int64(2112), 'contain': np.int64(553), 'bad': np.int64(230), 'behavior': np.int64(263), 'rarely': np.int64(2123), 'typically': np.int64(2778), 'entire': np.int64(878), 'discretization': np.int64(752), 'essential': np.int64(896), 'leave': np.int64(1502), 'disjoint': np.int64(758), 'us': np.int64(2840), 'supplemental': np.int64(2612), 'baran': np.int64(243), 'popović': np.int64(1966), 'balance': np.int64(233), 'sparsity': np.int64(2496), 'merge': np.int64(1652), 'intermediate': np.int64(1360), 'accordance': np.int64(15), 'unreduced': np.int64(2823), 'reduced': np.int64(2169), 'intractable': np.int64(1375), 'embedded': np.int64(850), 'impact': np.int64(1233), 'bottom': np.int64(308), 'mark': np.int64(1610), 'simultaneously': np.int64(2437), 'independently': np.int64(1281), 'proper': np.int64(2060), 'weighting': np.int64(2935), 'global': np.int64(1115), 'term': np.int64(2664), 'improper': np.int64(1250), 'length': np.int64(1507), 'symmetric': np.int64(2631), 'share': np.int64(2394), 'away': np.int64(223), 'far': np.int64(988), 'tutorial': np.int64(2769), 'burges': np.int64(347), 'machine': np.int64(1580), 'maximum': np.int64(1630), 'margin': np.int64(1608), 'classifier': np.int64(428), 'classify': np.int64(429), 'think': np.int64(2686), 'training': np.int64(2732), 'total': np.int64(2716), 'distinguish': np.int64(769), 'wish': np.int64(2953), 'maximize': np.int64(1629), 'necessarily': np.int64(1747), 'classification': np.int64(427), 'structured': np.int64(2568), 'label': np.int64(1465), 'possibility': np.int64(1977), 'finger': np.int64(1019), 'prevent': np.int64(2017), 'convex': np.int64(578), 'appear': np.int64(140), 'acceptable': np.int64(8), 'dimension': np.int64(733), 'feasible': np.int64(995), 'positive': np.int64(1976), 'chosen': np.int64(417), 'inadequate': np.int64(1257), 'accomplish': np.int64(13), 'examine': np.int64(919), 'exponentially': np.int64(954), 'partial': np.int64(1881), 'maintain': np.int64(1588), 'priority': np.int64(2031), 'queue': np.int64(2105), 'full': np.int64(1074), 'essentially': np.int64(897), 'reject': np.int64(2190), 'immediately': np.int64(1231), 'insert': np.int64(1323), 'match': np.int64(1619), 'faster': np.int64(991), 'index': np.int64(1282), 'parent': np.int64(1878), 'min': np.int64(1674), 'true': np.int64(2756), 'sum': np.int64(2604), 'lead': np.int64(1492), 'accurate': np.int64(20), 'manual': np.int64(1601), 'might': np.int64(1669), 'incorrectly': np.int64(1269), 'orient': np.int64(1840), 'refinement': np.int64(2177), 'deal': np.int64(647), 'four': np.int64(1057), 'convergence': np.int64(576), 'various': np.int64(2869), 'widespread': np.int64(2947), 'property': np.int64(2062), 'desire': np.int64(700), 'transition': np.int64(2739), 'meet': np.int64(1645), 'folding': np.int64(1042), 'purely': np.int64(2086), 'fail': np.int64(981), 'torso': np.int64(2715), 'heat': np.int64(1162), 'equilibrium': np.int64(890), 'temperature': np.int64(2652), 'solves': np.int64(2482), 'near': np.int64(1744), 'hw': np.int64(1201), 'laplacian': np.int64(1478), 'calculate': np.int64(354), 'meyer': np.int64(1664), 'jj': np.int64(1419), 'factor': np.int64(980), 'sparse': np.int64(2493), 'side': np.int64(2412), 'show': np.int64(2410), 'solver': np.int64(2481), 'kind': np.int64(1448), 'library': np.int64(1518), 'yield': np.int64(2984), 'slightly': np.int64(2463), 'variant': np.int64(2864), 'correctly': np.int64(593), 'demonstrate': np.int64(677), 'tolerate': np.int64(2706), 'walk': np.int64(2918), 'onto': np.int64(1825), 'thin': np.int64(2684), 'limb': np.int64(1528), 'hope': np.int64(1191), 'extremely': np.int64(973), 'disconnect': np.int64(745), 'video': np.int64(2886), 'deficiency': np.int64(658), 'automated': np.int64(211), 'class': np.int64(425), 'material': np.int64(1621), 'dress': np.int64(793), 'rubbery': np.int64(2303), 'core': np.int64(587), 'create': np.int64(610), 'triangle': np.int64(2751), 'subsequent': np.int64(2581), 'running': np.int64(2309), 'stage': np.int64(2528), 'consume': np.int64(550), 'quickly': np.int64(2107), 'context': np.int64(556), 'greatly': np.int64(1135), 'possibly': np.int64(1979), 'error': np.int64(894), 'involved': np.int64(1395), 'build': np.int64(336), 'tetrahedral': np.int64(2669), 'around': np.int64(164), 'dynamic': np.int64(805), 'capell': np.int64(365), 'physically': np.int64(1931), 'language': np.int64(1476), 'variety': np.int64(2868), 'facial': np.int64(977), 'succeed': np.int64(2591), 'begin': np.int64(259), 'interact': np.int64(1349), 'arikan': np.int64(160), 'topic': np.int64(2709), 'animal': np.int64(124), 'structural': np.int64(2566), 'inevitably': np.int64(1300), 'realism': np.int64(2138), 'importance': np.int64(1242), 'intuitiveness': np.int64(1385), 'interaction': np.int64(1350), 'computational': np.int64(508), 'subdivision': np.int64(2578), 'polygon': np.int64(1960), 'inefficient': np.int64(1295), 'layer': np.int64(1488), 'dense': np.int64(679), 'fine': np.int64(1017), 'detail': np.int64(705), 'wrinkle': np.int64(2973), 'behaviour': np.int64(264), 'tissue': np.int64(2702), 'mimic': np.int64(1673), 'intuitively': np.int64(1384), 'rapidly': np.int64(2121), 'group': np.int64(1140), 'similarity': np.int64(2423), 'categorize': np.int64(380), 'significantly': np.int64(2418), 'living': np.int64(1551), 'anatomical': np.int64(117), 'fat': np.int64(992), 'properly': np.int64(2061), 'mechanical': np.int64(1639), 'collision': np.int64(464), 'among': np.int64(108), 'excessive': np.int64(926), 'severe': np.int64(2389), 'restriction': np.int64(2253), 'driven': np.int64(796), 'workflow': np.int64(2961), 'couple': np.int64(604), 'accord': np.int64(14), 'external': np.int64(965), 'subject': np.int64(2580), 'stiffness': np.int64(2546), 'network': np.int64(1759), 'bulge': np.int64(338), 'bind': np.int64(284), 'traditional': np.int64(2728), 'deformer': np.int64(666), 'compatible': np.int64(482), 'software': np.int64(2475), 'regardless': np.int64(2183), 'whether': np.int64(2940), 'acting': np.int64(30), 'net': np.int64(1758), 'bar': np.int64(241), 'stretch': np.int64(2560), 'positioning': np.int64(1975), 'link': np.int64(1542), 'subdivide': np.int64(2577), 'patch': np.int64(1893), 'reach': np.int64(2131), 'author': np.int64(207), 'recreate': np.int64(2161), 'let': np.int64(1511), 'impossible': np.int64(1247), 'mission': np.int64(1686), 'connection': np.int64(527), 'implicit': np.int64(1239), 'meaning': np.int64(1634), 'outcome': np.int64(1851), 'computationally': np.int64(509), 'expensive': np.int64(943), 'refer': np.int64(2174), 'question': np.int64(2103), 'long': np.int64(1565), 'turn': np.int64(2768), 'strength': np.int64(2558), 'inspired': np.int64(1329), 'engineering': np.int64(868), 'realistically': np.int64(2140), 'operate': np.int64(1827), 'film': np.int64(1010), 'industry': np.int64(1293), 'rough': np.int64(2299), 'clear': np.int64(431), 'ffds': np.int64(1001), 'later': np.int64(1484), 'attempt': np.int64(198), 'simulate': np.int64(2432), 'develop': np.int64(711), 'wrap': np.int64(2971), 'deformers': np.int64(667), 'intuitive': np.int64(1383), 'history': np.int64(1182), 'shell': np.int64(2401), 'tedious': np.int64(2650), 'paint': np.int64(1864), 'suffers': np.int64(2598), 'candy': np.int64(361), 'wrapper': np.int64(2972), 'lack': np.int64(1469), 'consideration': np.int64(538), 'preservation': np.int64(2014), 'overcome': np.int64(1856), 'appearance': np.int64(141), 'dictate': np.int64(719), 'achieve': np.int64(23), 'gain': np.int64(1080), 'popularity': np.int64(1968), 'reproduce': np.int64(2224), 'abstract': np.int64(3), 'employ': np.int64(857), 'indirect': np.int64(1286), 'underneath': np.int64(2793), 'anticipate': np.int64(136), 'behave': np.int64(261), 'piece': np.int64(1934), 'elastic': np.int64(838), 'numerical': np.int64(1796), 'unlike': np.int64(2811), 'curved': np.int64(629), 'restrict': np.int64(2251), 'quadrilateral': np.int64(2095), 'analytically': np.int64(115), 'regard': np.int64(2182), 'worry': np.int64(2964), 'mechanism': np.int64(1641), 'unchanged': np.int64(2782), 'sense': np.int64(2367), 'separately': np.int64(2372), 'superposition': np.int64(2610), 'load': np.int64(1553), 'benefit': np.int64(273), 'affect': np.int64(74), 'finding': np.int64(1016), 'numerically': np.int64(1797), 'state': np.int64(2537), 'trivially': np.int64(2755), 'magnitude': np.int64(1584), 'quantity': np.int64(2099), 'ratio': np.int64(2126), 'satisfies': np.int64(2322), 'density': np.int64(680), 'added': np.int64(51), 'mechanically': np.int64(1640), 'compensate': np.int64(484), 'forearm': np.int64(1049), 'bend': np.int64(270), 'towards': np.int64(2718), 'relatively': np.int64(2197), 'unnoticeable': np.int64(2817), 'biceps': np.int64(280), 'brachii': np.int64(316), 'resource': np.int64(2242), 'typical': np.int64(2777), 'geometrically': np.int64(1107), 'topologically': np.int64(2712), 'frequently': np.int64(1068), 'capable': np.int64(364), 'connectivity': np.int64(528), 'three': np.int64(2690), 'applicable': np.int64(143), 'attract': np.int64(201), 'last': np.int64(1482), 'decade': np.int64(648), 'cpu': np.int64(608), 'intensive': np.int64(1347), 'emerge': np.int64(853), 'motivate': np.int64(1713), 'devise': np.int64(716), 'ideal': np.int64(1209), 'achieves': np.int64(24), 'primitive': np.int64(2024), 'efficiently': np.int64(825), 'currently': np.int64(626), 'interface': np.int64(1357), 'sequence': np.int64(2374), 'impractical': np.int64(1248), 'hierarchical': np.int64(1174), 'fundamental': np.int64(1078), 'authoring': np.int64(208), 'substructure': np.int64(2588), 'tendon': np.int64(2661), 'wilhelms': np.int64(2948), 'gelder': np.int64(1092), 'scheepers': np.int64(2335), 'custom': np.int64(630), 'script': np.int64(2344), 'wire': np.int64(2952), 'singh': np.int64(2440), 'fiume': np.int64(1024), 'continually': np.int64(557), 'highly': np.int64(1177), 'tightly': np.int64(2696), 'direct': np.int64(736), 'compact': np.int64(476), 'runtime': np.int64(2310), 'display': np.int64(762), 'required': np.int64(2230), 'priori': np.int64(2030), 'prohibitive': np.int64(2050), 'land': np.int64(1473), 'stair': np.int64(2531), 'lose': np.int64(1572), 'compactly': np.int64(477), 'trained': np.int64(2731), 'intend': np.int64(1345), 'freedom': np.int64(1065), 'sampling': np.int64(2318), 'perspective': np.int64(1923), 'invoke': np.int64(1393), 'rich': np.int64(2273), 'introduced': np.int64(1380), 'bilinear': np.int64(282), 'burtnyk': np.int64(349), 'beyond': np.int64(277), 'magnenatthalmann': np.int64(1583), 'novel': np.int64(1792), 'eigenskin': np.int64(831), 'scan': np.int64(2330), 'discard': np.int64(744), 'scale': np.int64(2328), 'james': np.int64(1414), 'pai': np.int64(1863), 'secondary': np.int64(2354), 'mwe': np.int64(1736), 'coefficient': np.int64(452), 'leastsquares': np.int64(1501), 'extension': np.int64(960), 'overfitting': np.int64(1857), 'measure': np.int64(1636), 'explicitly': np.int64(949), 'provision': np.int64(2073), 'detect': np.int64(707), 'entry': np.int64(881), 'infrastructure': np.int64(1311), 'excellent': np.int64(922), 'description': np.int64(694), 'affine': np.int64(75), 'characteristic': np.int64(405), 'nearly': np.int64(1746), 'environment': np.int64(884), 'resulting': np.int64(2257), 'observe': np.int64(1805), 'hinge': np.int64(1179), 'twisting': np.int64(2774), 'sometimes': np.int64(2484), 'appropriately': np.int64(149), 'severely': np.int64(2390), 'unclear': np.int64(2783), 'knowledge': np.int64(1457), 'believe': np.int64(267), 'beneficial': np.int64(272), 'thus': np.int64(2693), 'observation': np.int64(1804), 'evenly': np.int64(908), 'distribute': np.int64(771), 'locate': np.int64(1559), 'bent': np.int64(274), 'bicep': np.int64(279), 'flexion': np.int64(1032), 'upstream': np.int64(2835), 'driver': np.int64(797), 'conservative': np.int64(533), 'augment': np.int64(205), 'ideally': np.int64(1210), 'fall': np.int64(984), 'naturally': np.int64(1741), 'limited': np.int64(1531), 'select': np.int64(2362), 'rigidly': np.int64(2280), 'heavily': np.int64(1163), 'truly': np.int64(2757), 'mostly': np.int64(1711), 'collection': np.int64(461), 'cloud': np.int64(445), 'log': np.int64(1564), 'boissonnat': np.int64(303), 'tempt': np.int64(2657), 'threshold': np.int64(2691), 'problematic': np.int64(2036), 'pick': np.int64(1933), 'rigidity': np.int64(2279), 'score': np.int64(2342), 'meaningful': np.int64(1635), 'particularly': np.int64(1886), 'eight': np.int64(834), 'ith': np.int64(1409), 'guess': np.int64(1147), 'initial': np.int64(1316), 'iteration': np.int64(1406), 'robustness': np.int64(2289), 'fraction': np.int64(1060), 'paper': np.int64(1870), 'approximation': np.int64(152), 'light': np.int64(1523), 'calculation': np.int64(355), 'corresponding': np.int64(598), 'valid': np.int64(2851), 'neighborhood': np.int64(1755), 'pure': np.int64(2085), 'incrementally': np.int64(1274), 'composition': np.int64(499), 'alleviate': np.int64(89), 'convincing': np.int64(580), 'retain': np.int64(2258), 'interpenetration': np.int64(1362), 'subtle': np.int64(2589), 'convince': np.int64(579), 'five': np.int64(1025), 'minute': np.int64(1682), 'modern': np.int64(1697), 'parallelize': np.int64(1873), 'map': np.int64(1604), 'originally': np.int64(1843), 'retargeting': np.int64(2260), 'optimize': np.int64(1834), 'engine': np.int64(867), 'interactively': np.int64(1352), 'version': np.int64(2878), 'accurately': np.int64(21), 'representable': np.int64(2221), 'fully': np.int64(1075), 'violate': np.int64(2889), 'phenomenon': np.int64(1927), 'interplay': np.int64(1363), 'musculature': np.int64(1731), 'govern': np.int64(1121), 'algorithmic': np.int64(86), 'zara': np.int64(2988), 'inertial': np.int64(1298), 'chadwick': np.int64(397), 'chen': np.int64(410), 'zeltzer': np.int64(2990), 'sifakis': np.int64(2413), 'seek': np.int64(2358), 'gap': np.int64(1085), 'morph': np.int64(1709), 'derivative': np.int64(689), 'polynomial': np.int64(1962), 'modal': np.int64(1692), 'reduction': np.int64(2171), 'constitutive': np.int64(544), 'response': np.int64(2246), 'wrinkling': np.int64(2974), 'guide': np.int64(1148), 'extensive': np.int64(961), 'primarily': np.int64(2022), 'significant': np.int64(2417), 'survey': np.int64(2621), 'database': np.int64(643), 'maestro': np.int64(1582), 'twigg': np.int64(2772), 'predefined': np.int64(2001), 'hodgins': np.int64(1185), 'permit': np.int64(1920), 'sculpting': np.int64(2347), 'reputation': np.int64(2228), 'hybrid': np.int64(1202), 'morphing': np.int64(1710), 'posespace': np.int64(1972), 'kurihara': np.int64(1463), 'miyata': np.int64(1691), 'rhee': np.int64(2270), 'largely': np.int64(1480), 'related': np.int64(2193), 'mass': np.int64(1617), 'concept': np.int64(515), 'biomechanical': np.int64(287), 'broad': np.int64(326), 'aim': np.int64(80), 'zordan': np.int64(2996), 'trade': np.int64(2726), 'terzopoulos': np.int64(2666), 'witkin': np.int64(2956), 'metaxas': np.int64(1659), 'müller': np.int64(1737), 'gross': np.int64(1138), 'galoppo': np.int64(1083), 'welch': np.int64(2936), 'sculpted': np.int64(2346), 'recently': np.int64(2152), 'keyframes': np.int64(1444), 'retarget': np.int64(2259), 'enhance': np.int64(869), 'bergou': np.int64(275), 'simulated': np.int64(2433), 'prove': np.int64(2071), 'exploit': np.int64(950), 'integration': np.int64(1342), 'barbic': np.int64(244), 'mainly': np.int64(1587), 'eigenmodes': np.int64(830), 'controllable': np.int64(570), 'plasticity': np.int64(1949), 'notion': np.int64(1790), 'velocity': np.int64(2875), 'contact': np.int64(552), 'activation': np.int64(33), 'stiff': np.int64(2544), 'react': np.int64(2132), 'expose': np.int64(955), 'energy': np.int64(864), 'past': np.int64(1892), 'certainly': np.int64(394), 'formulation': np.int64(1053), 'strain': np.int64(2555), 'traditionally': np.int64(2729), 'account': np.int64(16), 'discretize': np.int64(754), 'differential': np.int64(723), 'solid': np.int64(2478), 'continuum': np.int64(562), 'mechanic': np.int64(1638), 'opt': np.int64(1831), 'multivariate': np.int64(1728), 'completely': np.int64(490), 'reduces': np.int64(2170), 'noticeable': np.int64(1789), 'experiment': np.int64(945), 'elasticity': np.int64(840), 'image': np.int64(1226), 'unless': np.int64(2810), 'note': np.int64(1786), 'amenable': np.int64(107), 'across': np.int64(28), 'modify': np.int64(1700), 'safely': np.int64(2313), 'metric': np.int64(1663), 'observed': np.int64(1806), 'continuously': np.int64(561), 'rbfs': np.int64(2130), 'suit': np.int64(2602), 'dimensional': np.int64(734), 'coupling': np.int64(605), 'globally': np.int64(1116), 'kernel': np.int64(1440), 'sparsely': np.int64(2494), 'scattered': np.int64(2332), 'locally': np.int64(1558), 'carr': np.int64(375), 'unable': np.int64(2779), 'extrapolate': np.int64(969), 'apart': np.int64(137), 'gaussian': np.int64(1090), 'smoothing': np.int64(2470), 'vectorial': np.int64(2874), 'unknowns': np.int64(2809), 'plus': np.int64(1956), 'unknown': np.int64(2808), 'combined': np.int64(470), 'underdetermined': np.int64(2788), 'redundancy': np.int64(2172), 'descriptor': np.int64(696), 'eqn': np.int64(886), 'loan': np.int64(1554), 'eigenvalue': np.int64(832), 'mapping': np.int64(1605), 'effective': np.int64(819), 'facilitate': np.int64(978), 'technical': np.int64(2647), 'director': np.int64(740), 'jacobian': np.int64(1412), 'evaluation': np.int64(906), 'costly': np.int64(601), 'stvk': np.int64(2572), 'dependency': np.int64(683), 'uq': np.int64(2839), 'tangent': np.int64(2642), 'cubic': np.int64(622), 'ij': np.int64(1219), 'ijk': np.int64(1220), 'li': np.int64(1517), 'precomputed': np.int64(1999), 'interpolator': np.int64(1368), 'aforementioned': np.int64(77), 'painting': np.int64(1865), 'young': np.int64(2986), 'modulus': np.int64(1704), 'poisson': np.int64(1958), 'offset': np.int64(1818), 'conceptually': np.int64(516), 'preprocessing': np.int64(2009), 'orthogonal': np.int64(1845), 'straight': np.int64(2553), 'eigenvectors': np.int64(833), 'care': np.int64(370), 'shear': np.int64(2398), 'put': np.int64(2090), 'mask': np.int64(1616), 'normalization': np.int64(1780), 'variance': np.int64(2863), 'fig': np.int64(1005), 'herbert': np.int64(1167), 'dramatic': np.int64(787), 'viewpoint': np.int64(2888), 'jump': np.int64(1427), 'dive': np.int64(775), 'flip': np.int64(1034), 'belly': np.int64(268), 'throughout': np.int64(2692), 'upright': np.int64(2833), 'tweaking': np.int64(2771), 'distinct': np.int64(767), 'fold': np.int64(1041), 'scenario': np.int64(2333), 'chest': np.int64(412), 'marginal': np.int64(1609), 'precomputation': np.int64(1998), 'never': np.int64(1763), 'slight': np.int64(2462), 'stable': np.int64(2527), 'satisfactory': np.int64(2320), 'comparison': np.int64(481), 'eq': np.int64(885), 'effectively': np.int64(820), 'contraction': np.int64(565), 'musculoskeletal': np.int64(1732), 'feature': np.int64(996), 'future': np.int64(1079), 'improved': np.int64(1252), 'localized': np.int64(1557), 'de': np.int64(646), 'technology': np.int64(2649), 'kinematics': np.int64(1450), 'integrate': np.int64(1340), 'pipeline': np.int64(1937), 'circumvent': np.int64(423), 'interactivity': np.int64(1353), 'integral': np.int64(1339), 'abandon': np.int64(0), 'familiar': np.int64(985), 'arises': np.int64(162), 'fashion': np.int64(989), 'lot': np.int64(1574), 'upon': np.int64(2831), 'entirely': np.int64(879), 'pattern': np.int64(1897), 'centre': np.int64(391), 'rate': np.int64(2124), 'ordinary': np.int64(1839), 'familiarity': np.int64(986), 'subset': np.int64(2583), 'visualization': np.int64(2899), 'reconstruction': np.int64(2158), 'confuse': np.int64(524), 'neither': np.int64(1757), 'ik': np.int64(1221), 'spline': np.int64(2517), 'undergo': np.int64(2790), 'kokkevis': np.int64(1459), 'derive': np.int64(690), 'module': np.int64(1703), 'detection': np.int64(708), 'resort': np.int64(2241), 'physic': np.int64(1929), 'level': np.int64(1512), 'expense': np.int64(942), 'discretized': np.int64(755), 'evolve': np.int64(915), 'correlation': np.int64(595), 'least': np.int64(1500), 'square': np.int64(2522), 'train': np.int64(2730), 'statistical': np.int64(2539), 'supply': np.int64(2613), 'variation': np.int64(2865), 'unrelated': np.int64(2824), 'described': np.int64(693), 'rectify': np.int64(2164), 'desirable': np.int64(699), 'thereby': np.int64(2682), 'seamless': np.int64(2350), 'plane': np.int64(1943), 'depict': np.int64(686), 'hierarchy': np.int64(1175), 'accommodate': np.int64(11), 'infinite': np.int64(1305), 'nonlinearity': np.int64(1777), 'copy': np.int64(585), 'voxelized': np.int64(2916), 'predict': np.int64(2002), 'check': np.int64(409), 'curvature': np.int64(627), 'float': np.int64(1035), 'central': np.int64(390), 'cross': np.int64(616), 'play': np.int64(1951), 'role': np.int64(2290), 'distribution': np.int64(772), 'normally': np.int64(1783), 'settle': np.int64(2385), 'challenging': np.int64(402), 'delaunay': np.int64(673), 'tetrahedralization': np.int64(2670), 'summation': np.int64(2607), 'cheap': np.int64(407), 'worsen': np.int64(2965), 'arise': np.int64(161), 'third': np.int64(2687), 'sophisticated': np.int64(2486), 'expand': np.int64(937), 'functionality': np.int64(1077), 'studio': np.int64(2569), 'activate': np.int64(32), 'cluster': np.int64(446), 'closely': np.int64(439), 'mathematically': np.int64(1623), 'consistency': np.int64(540), 'successfully': np.int64(2594), 'modification': np.int64(1698), 'utilize': np.int64(2848), 'slide': np.int64(2461), 'thalmann': np.int64(2677), 'reaction': np.int64(2133), 'zhang': np.int64(2992), 'incompressible': np.int64(1264), 'adjacent': np.int64(60), 'integrated': np.int64(1341), 'bear': np.int64(255), 'evolution': np.int64(914), 'membrane': np.int64(1647), 'arguably': np.int64(159), 'actively': np.int64(35), 'reflectance': np.int64(2179), 'scope': np.int64(2341), 'impressive': np.int64(1249), 'considerable': np.int64(536), 'spatially': np.int64(2498), 'visualize': np.int64(2900), 'reasonably': np.int64(2148), 'expressive': np.int64(958), 'deliver': np.int64(674), 'komatsu': np.int64(1460), 'discussion': np.int64(757), 'acute': np.int64(42), 'perhaps': np.int64(1915), 'variability': np.int64(2861), 'bending': np.int64(271), 'responsibility': np.int64(2247), 'specification': np.int64(2502), 'active': np.int64(34), 'investigation': np.int64(1391), 'notable': np.int64(1784), 'investigate': np.int64(1390), 'depth': np.int64(687), 'spring': np.int64(2520), 'van': np.int64(2858), 'conservation': np.int64(532), 'preliminary': np.int64(2006), 'promising': np.int64(2055), 'procedural': np.int64(2037), 'achievable': np.int64(22), 'identical': np.int64(1211), 'effectiveness': np.int64(821), 'inconsistent': np.int64(1266), 'neutral': np.int64(1762), 'publish': np.int64(2081), 'fact': np.int64(979), 'indirectly': np.int64(1287), 'consequently': np.int64(531), 'poor': np.int64(1964), 'understanding': np.int64(2795), 'since': np.int64(2439), 'whereby': np.int64(2939), 'procedurally': np.int64(2038), 'sheet': np.int64(2400), 'differs': np.int64(726), 'williams': np.int64(2949), 'neural': np.int64(1761), 'learning': np.int64(1499), 'excessively': np.int64(927), 'merely': np.int64(1651), 'intrinsic': np.int64(1377), 'dependence': np.int64(682), 'setting': np.int64(2384), 'emphasis': np.int64(854), 'opposite': np.int64(1830), 'ago': np.int64(79), 'deep': np.int64(655), 'shallow': np.int64(2392), 'promise': np.int64(2054), 'justify': np.int64(1431), 'consequent': np.int64(530), 'criterion': np.int64(614), 'introduction': np.int64(1382), 'projection': np.int64(2053), 'interpolant': np.int64(1364), 'fourier': np.int64(1058), 'series': np.int64(2378), 'φw': np.int64(2999), 'span': np.int64(2492), 'powerful': np.int64(1988), 'hold': np.int64(1186), 'everywhere': np.int64(911), 'except': np.int64(923), 'equivalently': np.int64(893), 'deviation': np.int64(714), 'initially': np.int64(1319), 'top': np.int64(2708), 'discontinuously': np.int64(748), 'discontinuous': np.int64(747), 'decide': np.int64(650), 'craft': np.int64(609), 'ensure': np.int64(874), 'extent': np.int64(963), 'iterative': np.int64(1407), 'incur': np.int64(1275), 'lookup': np.int64(1568), 'euclidean': np.int64(902), 'compose': np.int64(496), 'overlap': np.int64(1859), 'spine': np.int64(2514), 'uniformly': np.int64(2803), 'si': np.int64(2411), 'ax': np.int64(224), 'dimensionality': np.int64(735), 'separate': np.int64(2371), 'simultaneous': np.int64(2436), 'back': np.int64(226), 'piecewise': np.int64(1935), 'carry': np.int64(376), 'switch': np.int64(2628), 'word': np.int64(2959), 'quick': np.int64(2106), 'intrinsically': np.int64(1378), 'automate': np.int64(210), 'inferior': np.int64(1304), 'complement': np.int64(487), 'independence': np.int64(1279), 'fleischer': np.int64(1029), 'brien': np.int64(324), 'rendering': np.int64(2214), 'unfortunately': np.int64(2799), 'lee': np.int64(1503), 'parameterization': np.int64(1875), 'cloth': np.int64(442), 'science': np.int64(2339), 'theory': np.int64(2681), 'vibration': np.int64(2884), 'recognition': np.int64(2153), 'vision': np.int64(2897), 'turk': np.int64(2767), 'capability': np.int64(363), 'illustrate': np.int64(1225), 'buckling': np.int64(334), 'clothing': np.int64(444), 'measurement': np.int64(1637), 'lindholm': np.int64(1534), 'pca': np.int64(1898), 'eigendisplacement': np.int64(827), 'decompose': np.int64(652), 'construction': np.int64(549), 'filtering': np.int64(1012), 'localize': np.int64(1556), 'imperceptible': np.int64(1234), 'perturbation': np.int64(1925), 'perturb': np.int64(1924), 'successive': np.int64(2595), 'truncate': np.int64(2758), 'expansion': np.int64(938), 'truncated': np.int64(2759), 'send': np.int64(2366), 'eigendisplacements': np.int64(828), 'jk': np.int64(1420), 'few': np.int64(1000), 'half': np.int64(1151), 'dozen': np.int64(785), 'programming': np.int64(2048), 'accumulation': np.int64(18), 'room': np.int64(2292), 'careful': np.int64(371), 'renderable': np.int64(2213), 'restricted': np.int64(2252), 'exhibit': np.int64(934), 'matching': np.int64(1620), 'loop': np.int64(1569), 'zienkiewicz': np.int64(2994), 'blood': np.int64(298), 'vessel': np.int64(2881), 'bulk': np.int64(340), 'alternate': np.int64(100), 'recover': np.int64(2160), 'articulate': np.int64(168), 'subtlety': np.int64(2590), 'biomechanics': np.int64(288), 'wpsd': np.int64(2970), 'skill': np.int64(2452), 'parallel': np.int64(1872), 'simd': np.int64(2421), 'architecture': np.int64(156), 'grows': np.int64(1142), 'date': np.int64(645), 'medical': np.int64(1643), 'skilled': np.int64(2453), 'estimation': np.int64(900), 'gpus': np.int64(1125), 'lhk': np.int64(1516), 'gpg': np.int64(1123), 'access': np.int64(9), 'fragment': np.int64(1061), 'processor': np.int64(2043), 'person': np.int64(1922), 'people': np.int64(1904), 'ask': np.int64(175), 'recognize': np.int64(2154), 'translate': np.int64(2740), 'normalized': np.int64(1782), 'equally': np.int64(888), 'contribute': np.int64(567), 'unexpected': np.int64(2797), 'elaborate': np.int64(837), 'dof': np.int64(779), 'clearly': np.int64(432), 'middle': np.int64(1667), 'storage': np.int64(2551), 'rgba': np.int64(2269), 'rgb': np.int64(2268), 'pass': np.int64(1890), 'six': np.int64(2447), 'ray': np.int64(2128), 'trace': np.int64(2719), 'attached': np.int64(193), 'buffer': np.int64(335), 'pas': np.int64(1889), 'array': np.int64(165), 'report': np.int64(2219), 'processing': np.int64(2042), 'cg': np.int64(396), 'loose': np.int64(1570), 'compression': np.int64(504), 'repertoire': np.int64(2217), 'motor': np.int64(1715), 'progress': np.int64(2049), 'controller': np.int64(572), 'maneuver': np.int64(1594), 'cop': np.int64(583), 'enormous': np.int64(871), 'controlled': np.int64(571), 'composite': np.int64(497), 'encapsulate': np.int64(860), 'robotics': np.int64(2286), 'specifically': np.int64(2501), 'thing': np.int64(2685), 'answer': np.int64(135), 'query': np.int64(2102), 'pool': np.int64(1963), 'manage': np.int64(1593), 'supervisor': np.int64(2611), 'precondition': np.int64(2000), 'characterize': np.int64(406), 'stuntperson': np.int64(2571), 'dangerous': np.int64(641), 'coherent': np.int64(455), 'reflect': np.int64(2178), 'adult': np.int64(65), 'male': np.int64(1592), 'rapid': np.int64(2120), 'prototyping': np.int64(2070), 'disturbance': np.int64(774), 'elicit': np.int64(846), 'though': np.int64(2688), 'autonomous': np.int64(214), 'intricacy': np.int64(1376), 'unprecedented': np.int64(2819), 'comprehensive': np.int64(501), 'evident': np.int64(913), 'tractable': np.int64(2724), 'source': np.int64(2489), 'experimental': np.int64(946), 'treatment': np.int64(2746), 'disability': np.int64(741), 'increasingly': np.int64(1272), 'remarkable': np.int64(2206), 'bipedal': np.int64(290), 'robotic': np.int64(2285), 'summary': np.int64(2606), 'warp': np.int64(2923), 'planning': np.int64(1944), 'dynamically': np.int64(807), 'vault': np.int64(2872), 'methodology': np.int64(1662), 'leap': np.int64(1496), 'laboratory': np.int64(1467), 'broadly': np.int64(327), 'stand': np.int64(2534), 'chair': np.int64(400), 'grow': np.int64(1141), 'integer': np.int64(1338), 'probability': np.int64(2033), 'becomes': np.int64(258), 'binary': np.int64(283), 'preference': np.int64(2005), 'burden': np.int64(346), 'designer': np.int64(698), 'abstraction': np.int64(4), 'walking': np.int64(2919), 'failure': np.int64(982), 'adhere': np.int64(58), 'denote': np.int64(678), 'gravity': np.int64(1133), 'unbalanced': np.int64(2781), 'crucial': np.int64(619), 'postconditions': np.int64(1981), 'selection': np.int64(2363), 'sudden': np.int64(2596), 'badly': np.int64(232), 'continue': np.int64(558), 'gait': np.int64(1081), 'interval': np.int64(1373), 'implicitly': np.int64(1240), 'rise': np.int64(2281), 'practically': np.int64(1992), 'respond': np.int64(2245), 'intervention': np.int64(1374), 'sit': np.int64(2444), 'via': np.int64(2882), 'study': np.int64(2570), 'sagittal': np.int64(2315), 'pendulum': np.int64(1902), 'stability': np.int64(2526), 'friction': np.int64(1069), 'protective': np.int64(2068), 'slip': np.int64(2464), 'svms': np.int64(2624), 'labeled': np.int64(1466), 'regression': np.int64(2187), 'encode': np.int64(861), 'svm': np.int64(2623), 'decision': np.int64(651), 'quadratic': np.int64(2092), 'lagrange': np.int64(1470), 'multiplier': np.int64(1726), 'reader': np.int64(2134), 'job': np.int64(1421), 'stochastic': np.int64(2548), 'randomized': np.int64(2115), 'randomize': np.int64(2114), 'learned': np.int64(1498), 'comprise': np.int64(505), 'thousand': np.int64(2689), 'proceeds': np.int64(2040), 'hour': np.int64(1193), 'mhz': np.int64(1665), 'millisecond': np.int64(1672), 'neighbor': np.int64(1754), 'closest': np.int64(441), 'nn': np.int64(1770), 'consistently': np.int64(542), 'outperform': np.int64(1852), 'dance': np.int64(639), 'simulator': np.int64(2435), 'actuator': np.int64(41), 'actor': np.int64(37), 'exert': np.int64(933), 'ground': np.int64(1139), 'optimized': np.int64(1835), 'fourth': np.int64(1059), 'integrator': np.int64(1343), 'exchange': np.int64(928), 'moment': np.int64(1706), 'inertia': np.int64(1297), 'enforce': np.int64(865), 'prefer': np.int64(2004), 'cyclic': np.int64(634), 'feedback': np.int64(998), 'parameterized': np.int64(1876), 'sensor': np.int64(2370), 'track': np.int64(2721), 'voluntary': np.int64(2910), 'enter': np.int64(876), 'ought': np.int64(1850), 'restore': np.int64(2250), 'ankle': np.int64(131), 'mind': np.int64(1675), 'shock': np.int64(2405), 'balanced': np.int64(234), 'frictional': np.int64(1070), 'flat': np.int64(1028), 'crouch': np.int64(618), 'prone': np.int64(2056), 'emulate': np.int64(858), 'roll': np.int64(2291), 'eventually': np.int64(909), 'kip': np.int64(1452), 'athletic': np.int64(189), 'martial': np.int64(1615), 'art': np.int64(166), 'ballistic': np.int64(237), 'kick': np.int64(1446), 'upward': np.int64(2836), 'takeoff': np.int64(2640), 'timing': np.int64(2701), 'mix': np.int64(1689), 'analytical': np.int64(114), 'prune': np.int64(2076), 'prediction': np.int64(2003), 'refine': np.int64(2176), 'obstacle': np.int64(1807), 'physicsbased': np.int64(1932), 'ameliorate': np.int64(106), 'freely': np.int64(1066), 'foster': np.int64(1056), 'spectrum': np.int64(2506), 'climb': np.int64(434), 'adaptable': np.int64(45), 'excite': np.int64(930), 'prospect': np.int64(2067), 'warrant': np.int64(2924), 'dofs': np.int64(780), 'reliably': np.int64(2202), 'law': np.int64(1487), 'colleague': np.int64(459), 'angular': np.int64(123), 'momentum': np.int64(1707), 'reformulate': np.int64(2181), 'torque': np.int64(2714), 'pollard': np.int64(1959), 'safonova': np.int64(2314), 'locomotion': np.int64(1563), 'forsyth': np.int64(1054), 'kovar': np.int64(1461), 'effector': np.int64(822), 'isolated': np.int64(1400), 'satisfied': np.int64(2321), 'kuriyama': np.int64(1464), 'markov': np.int64(1613), 'hilton': np.int64(1178), 'brand': np.int64(319), 'hertzmann': np.int64(1169), 'galata': np.int64(1082), 'bregler': np.int64(322), 'style': np.int64(2573), 'speech': np.int64(2507), 'signal': np.int64(2415), 'grzeszczuk': np.int64(1143), 'temporal': np.int64(2654), 'window': np.int64(2951), 'tracking': np.int64(2723), 'slds': np.int64(2457), 'grochow': np.int64(1137), 'chai': np.int64(398), 'reconstruct': np.int64(2156), 'camera': np.int64(359), 'scene': np.int64(2334), 'smoke': np.int64(2468), 'noise': np.int64(1773), 'prerecord': np.int64(2010), 'bishop': np.int64(291), 'drop': np.int64(798), 'theorem': np.int64(2678), 'arg': np.int64(158), 'max': np.int64(1628), 'ln': np.int64(1552), 'dynamical': np.int64(806), 'captured': np.int64(368), 'bu': np.int64(331), 'ambiguity': np.int64(104), 'uniquely': np.int64(2806), 'sequentially': np.int64(2376), 'kass': np.int64(1433), 'screen': np.int64(2343), 'rotoscoping': np.int64(2298), 'period': np.int64(1916), 'temporally': np.int64(2655), 'instantaneous': np.int64(1333), 'likelihood': np.int64(1526), 'cx': np.int64(632), 'generated': np.int64(1100), 'mixture': np.int64(1690), 'weak': np.int64(2928), 'unconstrained': np.int64(2787), 'sequential': np.int64(2375), 'bazaraa': np.int64(252), 'jumping': np.int64(1428), 'root': np.int64(2293), 'keyframe': np.int64(1442), 'instant': np.int64(1332), 'hop': np.int64(1190), 'mismatch': np.int64(1684), 'userdefined': np.int64(2845), 'reconstructed': np.int64(2157), 'unacceptable': np.int64(2780), 'constrained': np.int64(546), 'stylize': np.int64(2575), 'exploration': np.int64(951), 'immediate': np.int64(1230), 'appeal': np.int64(139), 'validity': np.int64(2854), 'sacrifice': np.int64(2312), 'alone': np.int64(94), 'swing': np.int64(2627), 'tuck': np.int64(2762), 'iteratively': np.int64(1408), 'differentiate': np.int64(724), 'bottleneck': np.int64(307), 'aggregate': np.int64(78), 'conserve': np.int64(534), 'flight': np.int64(1033), 'explain': np.int64(947), 'differentiation': np.int64(725), 'lagrangian': np.int64(1471), 'symbolic': np.int64(2629), 'rewrite': np.int64(2267), 'exclude': np.int64(931), 'squared': np.int64(2523), 'acceleration': np.int64(6), 'luxo': np.int64(1578), 'cohen': np.int64(453), 'incremental': np.int64(1273), 'pandy': np.int64(1867), 'height': np.int64(1165), 'editing': np.int64(817), 'shin': np.int64(2403), 'correctness': np.int64(594), 'yamane': np.int64(2979), 'plan': np.int64(1941), 'badler': np.int64(231), 'panne': np.int64(1868), 'optimizer': np.int64(1836), 'inequality': np.int64(1296), 'elegant': np.int64(844), 'illegal': np.int64(1223), 'pull': np.int64(2083), 'unreasonable': np.int64(2822), 'pressure': np.int64(2016), 'confine': np.int64(521), 'notation': np.int64(1785), 'usual': np.int64(2846), 'recursion': np.int64(2166), 'depends': np.int64(685), 'collect': np.int64(460), 'propagation': np.int64(2059), 'leaf': np.int64(1494), 'intermediary': np.int64(1359), 'appendix': np.int64(142), 'serial': np.int64(2377), 'consumption': np.int64(551), 'kd': np.int64(1438), 'expenditure': np.int64(941), 'dt': np.int64(800), 'hessian': np.int64(1170), 'definite': np.int64(660), 'jerk': np.int64(1415), 'unstable': np.int64(2825), 'slice': np.int64(2460), 'finer': np.int64(1018), 'overly': np.int64(1860), 'sparser': np.int64(2495), 'alter': np.int64(98), 'flow': np.int64(1037), 'restrictive': np.int64(2254), 'toward': np.int64(2717), 'activity': np.int64(36), 'fill': np.int64(1007), 'stride': np.int64(2563), 'favorable': np.int64(994), 'advance': np.int64(67), 'acquisition': np.int64(26), 'record': np.int64(2159), 'live': np.int64(1549), 'voice': np.int64(2905), 'leader': np.int64(1493), 'follower': np.int64(1044), 'minimally': np.int64(1677), 'dancer': np.int64(640), 'precise': np.int64(1996), 'semantically': np.int64(2364), 'instance': np.int64(1331), 'partner': np.int64(1888), 'backward': np.int64(228), 'interpretation': np.int64(1370), 'assemble': np.int64(177), 'continuity': np.int64(559), 'induced': np.int64(1292), 'postprocessing': np.int64(1982), 'mouse': np.int64(1716), 'tremendous': np.int64(2748), 'offline': np.int64(1817), 'defy': np.int64(669), 'probabilistic': np.int64(2032), 'worthwhile': np.int64(2967), 'tradeoff': np.int64(2727), 'kim': np.int64(1447), 'segmentation': np.int64(2361), 'rhythmic': np.int64(2272), 'pullen': np.int64(2084), 'texturing': np.int64(2674), 'keyframed': np.int64(1443), 'enforcement': np.int64(866), 'admit': np.int64(63), 'annotation': np.int64(133), 'intent': np.int64(1348), 'clip': np.int64(435), 'inspiration': np.int64(1327), 'analogous': np.int64(111), 'applies': np.int64(145), 'rule': np.int64(2306), 'rhythm': np.int64(2271), 'beat': np.int64(256), 'quantify': np.int64(2098), 'vertical': np.int64(2880), 'closed': np.int64(438), 'descriptive': np.int64(695), 'duration': np.int64(803), 'kc': np.int64(1437), 'legal': np.int64(1506), 'asymptotic': np.int64(187), 'inefficiency': np.int64(1294), 'redundant': np.int64(2173), 'beam': np.int64(254), 'upsampling': np.int64(2834), 'introduces': np.int64(1381), 'remedy': np.int64(2209), 'raw': np.int64(2127), 'handhold': np.int64(1154), 'annotate': np.int64(132), 'compelling': np.int64(483), 'lindy': np.int64(1535), 'footage': np.int64(1047), 'artificially': np.int64(173), 'floor': np.int64(1036), 'frequency': np.int64(1067), 'sharp': np.int64(2395), 'draw': np.int64(791), 'minor': np.int64(1681), 'option': np.int64(1837), 'trial': np.int64(2750), 'principled': np.int64(2027), 'stance': np.int64(2533), 'crosshand': np.int64(617), 'instantly': np.int64(1335), 'seven': np.int64(2387), 'violation': np.int64(2890), 'synthetic': np.int64(2635), 'stylistic': np.int64(2574), 'synthesized': np.int64(2634), 'rearrange': np.int64(2144), 'accept': np.int64(7), 'reading': np.int64(2136), 'inherit': np.int64(1315), 'cue': np.int64(623), 'homogeneous': np.int64(1188), 'availability': np.int64(216), 'analyze': np.int64(116), 'summarize': np.int64(2605), 'ingredient': np.int64(1312), 'movie': np.int64(1719), 'background': np.int64(227), 'cut': np.int64(631), 'bit': np.int64(292), 'post': np.int64(1980), 'lengthen': np.int64(1508), 'penetrate': np.int64(1903), 'intelligent': np.int64(1344), 'overview': np.int64(1861), 'lamouret': np.int64(1472), 'roadmap': np.int64(2283), 'randomly': np.int64(2116), 'bowden': np.int64(312), 'directed': np.int64(737), 'splice': np.int64(2516), 'incident': np.int64(1259), 'perfectly': np.int64(1910), 'coarser': np.int64(450), 'branch': np.int64(317), 'pruning': np.int64(2077), 'random': np.int64(2113), 'paths': np.int64(1895), 'extremum': np.int64(974), 'mutation': np.int64(1735), 'seed': np.int64(2357), 'stick': np.int64(2543), 'coarse': np.int64(448), 'inclusion': np.int64(1261), 'imply': np.int64(1241), 'indicative': np.int64(1284), 'satisfaction': np.int64(2319), 'inherently': np.int64(1314), 'head': np.int64(1161), 'specified': np.int64(2503), 'unnatural': np.int64(2814), 'jerky': np.int64(1417), 'unconnected': np.int64(2786), 'linearity': np.int64(1538), 'dataset': np.int64(644), 'woody': np.int64(2958), 'incoming': np.int64(1262), 'acrobatic': np.int64(27), 'inaccuracy': np.int64(1255), 'spacetime': np.int64(2491), 'degradation': np.int64(670), 'adaptation': np.int64(46), 'landing': np.int64(1475), 'laborious': np.int64(1468), 'robust': np.int64(2287), 'spin': np.int64(2513), 'deviate': np.int64(713), 'hit': np.int64(1183), 'ball': np.int64(235), 'sensitivity': np.int64(2369), 'simplification': np.int64(2428), 'passive': np.int64(1891), 'ligament': np.int64(1522), 'release': np.int64(2199), 'usage': np.int64(2841), 'resultant': np.int64(2256), 'sound': np.int64(2488), 'adjustment': np.int64(62), 'gear': np.int64(1091), 'existence': np.int64(936), 'content': np.int64(555), 'band': np.int64(238), 'varies': np.int64(2867), 'gravitational': np.int64(1132), 'unnaturally': np.int64(2815), 'pseudo': np.int64(2079), 'lean': np.int64(1495), 'populate': np.int64(1969), 'fly': np.int64(1039), 'adequately': np.int64(57), 'perceptible': np.int64(1906), 'positional': np.int64(1974), 'drastic': np.int64(790), 'hopping': np.int64(1192), 'lower': np.int64(1576), 'preparation': np.int64(2008), 'modified': np.int64(1699), 'paradigm': np.int64(1871), 'primary': np.int64(2023), 'generalized': np.int64(1097), 'medium': np.int64(1644), 'reliable': np.int64(2201), 'travel': np.int64(2743), 'stream': np.int64(2557), 'performer': np.int64(1913), 'bruderlin': np.int64(329), 'complementary': np.int64(488), 'risk': np.int64(2282), 'tight': np.int64(2695), 'pursue': np.int64(2088), 'perlin': np.int64(1918), 'session': np.int64(2381), 'rudimentary': np.int64(2304), 'attainable': np.int64(197), 'schödl': np.int64(2338), 'empirically': np.int64(856), 'ballet': np.int64(236), 'indefinitely': np.int64(1278), 'arbitrarily': np.int64(153), 'sink': np.int64(2443), 'finally': np.int64(1014), 'interested': np.int64(1355), 'attain': np.int64(196), 'branching': np.int64(318), 'randomness': np.int64(2117), 'worth': np.int64(2966), 'spend': np.int64(2509), 'whatever': np.int64(2938), 'incentive': np.int64(1258), 'backwards': np.int64(229), 'subgraph': np.int64(2579), 'prevents': np.int64(2018), 'viable': np.int64(2883), 'march': np.int64(1606), 'conform': np.int64(522), 'hundred': np.int64(1200), 'consequence': np.int64(529), 'merit': np.int64(1654), 'retargetted': np.int64(2261), 'imitate': np.int64(1229), 'infinitely': np.int64(1306), 'omr': np.int64(1822), 'enhancement': np.int64(870), 'propagates': np.int64(2058), 'utilized': np.int64(2849), 'coherence': np.int64(454), 'resemble': np.int64(2235), 'imposes': np.int64(1246), 'cartesian': np.int64(377), 'respectively': np.int64(2244), 'clik': np.int64(433), 'instability': np.int64(1330), 'discrepancy': np.int64(750), 'clamp': np.int64(424), 'manipulative': np.int64(1599), 'closer': np.int64(440), 'destination': np.int64(703), 'remarkably': np.int64(2207), 'corner': np.int64(588), 'recommend': np.int64(2155), 'despite': np.int64(702), 'biological': np.int64(285), 'excitation': np.int64(929), 'musculotendon': np.int64(1733), 'fluid': np.int64(1038), 'fiber': np.int64(1002), 'biologically': np.int64(286), 'implausible': np.int64(1235), 'metabolic': np.int64(1658), 'initialization': np.int64(1317), 'mtus': np.int64(1720), 'truth': np.int64(2760), 'yin': np.int64(2985), 'jain': np.int64(1413), 'coros': np.int64(590), 'lasa': np.int64(1481), 'mordatch': np.int64(1708), 'wu': np.int64(2978), 'importantly': np.int64(1244), 'muico': np.int64(1722), 'ye': np.int64(2981), 'plantarflexion': np.int64(1946), 'actuate': np.int64(40), 'water': np.int64(2925), 'planar': np.int64(1942), 'ruina': np.int64(2305), 'reflex': np.int64(2180), 'geyer': np.int64(1111), 'herr': np.int64(1168), 'inspire': np.int64(1328), 'site': np.int64(2445), 'burnfield': np.int64(348), 'instantaneously': np.int64(1334), 'block': np.int64(297), 'gas': np.int64(1087), 'late': np.int64(1483), 'ta': np.int64(2637), 'hfl': np.int64(1173), 'damp': np.int64(637), 'initialize': np.int64(1318), 'sol': np.int64(2476), 'hyperextension': np.int64(1204), 'initiation': np.int64(1320), 'double': np.int64(784), 'modulate': np.int64(1701), 'coronal': np.int64(589), 'break': np.int64(320), 'tendency': np.int64(2660), 'timesteps': np.int64(2700), 'additionally': np.int64(54), 'ce': np.int64(386), 'readily': np.int64(2135), 'earlier': np.int64(808), 'dorsiflexion': np.int64(783), 'generates': np.int64(1101), 'plantarflexors': np.int64(1947), 'mild': np.int64(1670), 'weaken': np.int64(2929), 'quarter': np.int64(2100), 'accompany': np.int64(12), 'cerebral': np.int64(392), 'patient': np.int64(1896), 'surgery': np.int64(2618), 'quadriceps': np.int64(2094), 'va': np.int64(2850), 'peak': np.int64(1899), 'scientific': np.int64(2340), 'validation': np.int64(2853), 'emphasize': np.int64(855), 'generative': np.int64(1103), 'distinctive': np.int64(768), 'jerkiness': np.int64(1416), 'insufficient': np.int64(1337), 'stylized': np.int64(2576), 'heterogeneous': np.int64(1171), 'resistance': np.int64(2238), 'sneaky': np.int64(2472), 'prerecorded': np.int64(2011), 'ikemoto': np.int64(1222), 'attraction': np.int64(202), 'gp': np.int64(1122), 'invariant': np.int64(1386), 'leverage': np.int64(1514), 'newtonian': np.int64(1766), 'tuning': np.int64(2764), 'disturb': np.int64(773), 'confidence': np.int64(519), 'incorporation': np.int64(1268), 'join': np.int64(1422), 'viscoelastic': np.int64(2893), 'elastically': np.int64(839), 'stress': np.int64(2559), 'white': np.int64(2941), 'liquid': np.int64(1544), 'clay': np.int64(430), 'soap': np.int64(2473), 'bounce': np.int64(309), 'viscous': np.int64(2895), 'eulerian': np.int64(904), 'evidence': np.int64(912), 'rectilinear': np.int64(2165), 'staggered': np.int64(2530), 'advect': np.int64(70), 'von': np.int64(2911), 'mises': np.int64(1683), 'resist': np.int64(2237), 'incompressibility': np.int64(1263), 'damping': np.int64(638), 'presence': np.int64(2012), 'act': np.int64(29), 'regime': np.int64(2185), 'occurs': np.int64(1813), 'elastoplastic': np.int64(841), 'carlson': np.int64(374), 'viscosity': np.int64(2894), 'particle': np.int64(1883), 'desbrun': np.int64(691), 'gascuel': np.int64(1088), 'cani': np.int64(362), 'stora': np.int64(2550), 'plastic': np.int64(1948), 'premo': np.int64(2007), 'ze': np.int64(2989), 'tangle': np.int64(2643), 'stam': np.int64(2532), 'fedkiw': np.int64(997), 'enright': np.int64(873), 'extensively': np.int64(962), 'gerritsma': np.int64(1109), 'bonito': np.int64(305), 'tensor': np.int64(2663), 'rigidbody': np.int64(2278), 'levelset': np.int64(1513), 'stagger': np.int64(2529), 'avoids': np.int64(222), 'harlow': np.int64(1160), 'scalar': np.int64(2327), 'diagonal': np.int64(717), 'perpendicular': np.int64(1921), 'jet': np.int64(1418), 'container': np.int64(554), 'splash': np.int64(2515), 'collide': np.int64(462), 'ghost': np.int64(1112), 'vanish': np.int64(2859), 'cold': np.int64(457), 'hydrodynamics': np.int64(1203), 'working': np.int64(2962), 'sethian': np.int64(2383), 'osher': np.int64(1847), 'update': np.int64(2830), 'advected': np.int64(71), 'contour': np.int64(563), 'advection': np.int64(72), 'contouring': np.int64(564), 'color': np.int64(465), 'losasso': np.int64(1571), 'goktekin': np.int64(1119), 'hong': np.int64(1189), 'guendelman': np.int64(1146), 'zhu': np.int64(2993), 'bridson': np.int64(323), 'topological': np.int64(2711), 'bærentzen': np.int64(352), 'tracing': np.int64(2720), 'droplet': np.int64(799), 'puckett': np.int64(2082), 'voxel': np.int64(2915), 'tension': np.int64(2662), 'surfels': np.int64(2617), 'octrees': np.int64(1815), 'cubes': np.int64(621), 'dual': np.int64(801), 'ju': np.int64(1426), 'triangulation': np.int64(2753), 'prohibitively': np.int64(2051), 'timestep': np.int64(2698), 'manifold': np.int64(1596), 'cir': np.int64(419), 'unconditional': np.int64(2784), 'unconditionally': np.int64(2785), 'midpoint': np.int64(1668), 'euler': np.int64(903), 'altogether': np.int64(102), 'nearby': np.int64(1745), 'splitting': np.int64(2519), 'exterior': np.int64(964), 'signed': np.int64(2416), 'coarsen': np.int64(449), 'marching': np.int64(1607), 'redistancing': np.int64(2167), 'corresponds': np.int64(599), 'blur': np.int64(301), 'resampling': np.int64(2232), 'unwanted': np.int64(2829), 'barycentric': np.int64(247), 'tracker': np.int64(2722), 'colored': np.int64(466), 'neumann': np.int64(1760), 'today': np.int64(2703), 'journal': np.int64(1425), 'atmospheric': np.int64(191), 'mature': np.int64(1627), 'motivation': np.int64(1714), 'artificial': np.int64(172), 'compressibility': np.int64(502), 'justified': np.int64(1430), 'imagery': np.int64(1227), 'navierstokes': np.int64(1743), 'vorticity': np.int64(2914), 'atmosphere': np.int64(190), 'jupiter': np.int64(1429), 'creative': np.int64(612), 'compressible': np.int64(503), 'wave': np.int64(2926), 'vortex': np.int64(2913), 'buoyant': np.int64(345), 'meteorology': np.int64(1660), 'derivation': np.int64(688), 'buoyancy': np.int64(344), 'periodic': np.int64(1917), 'compositing': np.int64(498), 'convolution': np.int64(581), 'compositor': np.int64(500), 'disk': np.int64(759), 'seam': np.int64(2349), 'surround': np.int64(2620), 'please': np.int64(1953), 'distortion': np.int64(770), 'transport': np.int64(2742), 'upwind': np.int64(2837), 'semilagrangian': np.int64(2365), 'dissipation': np.int64(764), 'dilution': np.int64(732), 'cip': np.int64(418), 'bfecc': np.int64(278), 'remedied': np.int64(2208), 'dissipate': np.int64(763), 'dissipative': np.int64(765), 'diffusive': np.int64(731), 'tfk': np.int64(2675), 'sab': np.int64(2311), 'dye': np.int64(804), 'diffuse': np.int64(729), 'performs': np.int64(1914), 'upwinding': np.int64(2838), 'sizing': np.int64(2449), 'tetrahedron': np.int64(2671), 'meshing': np.int64(1657), 'alliez': np.int64(90), 'unstructured': np.int64(2826), 'irregular': np.int64(1397), 'remeshing': np.int64(2210), 'feldman': np.int64(999), 'conformance': np.int64(523), 'elcott': np.int64(843), 'ale': np.int64(83), 'regenerate': np.int64(2184), 'inviscid': np.int64(1392), 'terminate': np.int64(2665), 'divergence': np.int64(776), 'circumcenters': np.int64(421), 'graphical': np.int64(1131), 'variational': np.int64(2866), 'ensures': np.int64(875), 'blue': np.int64(300), 'valve': np.int64(2857), 'lively': np.int64(1550), 'eigenfunctions': np.int64(829), 'turbulent': np.int64(2766), 'decay': np.int64(649), 'calculus': np.int64(356), 'immersed': np.int64(1232), 'avenue': np.int64(218), 'vast': np.int64(2871), 'marsden': np.int64(1614), 'silberman': np.int64(2419), 'cfd': np.int64(395), 'symbolically': np.int64(2630), 'spectral': np.int64(2505), 'orszag': np.int64(1844), 'turbulence': np.int64(2765), 'tie': np.int64(2694), 'belong': np.int64(269), 'lentine': np.int64(1509), 'curl': np.int64(624), 'mullen': np.int64(1723), 'rectangle': np.int64(2162), 'rectangular': np.int64(2163), 'cavity': np.int64(383), 'adam': np.int64(43), 'sph': np.int64(2510), 'treuille': np.int64(2749), 'kinetic': np.int64(1451), 'adv': np.int64(66), 'bandlimited': np.int64(239), 'attenuate': np.int64(200), 'gradual': np.int64(1128), 'reversibility': np.int64(2264), 'adaptivity': np.int64(49), 'spurious': np.int64(2521), 'repair': np.int64(2215), 'batty': np.int64(251), 'mac': np.int64(1579), 'discretizations': np.int64(753), 'ando': np.int64(121), 'klingner': np.int64(1453), 'bcc': np.int64(253), 'chentanez': np.int64(411), 'misztal': np.int64(1688), 'brochu': np.int64(328), 'wider': np.int64(2946), 'averaged': np.int64(220), 'union': np.int64(2804), 'hull': np.int64(1196), 'tetrahedra': np.int64(2668), 'implication': np.int64(1238), 'locking': np.int64(1562), 'irving': np.int64(1398), 'lock': np.int64(1561), 'indefinite': np.int64(1277), 'revert': np.int64(2265), 'graded': np.int64(1126), 'particles': np.int64(1884), 'bumpy': np.int64(342), 'wojtan': np.int64(2957), 'rebuild': np.int64(2149), 'temporarily': np.int64(2656), 'intersection': np.int64(1372), 'extrapolation': np.int64(970), 'nodal': np.int64(1771), 'million': np.int64(1671), 'strongly': np.int64(2565), 'hole': np.int64(1187), 'bump': np.int64(341), 'indispensable': np.int64(1288), 'mid': np.int64(1666), 'air': np.int64(81), 'increased': np.int64(1271), 'wall': np.int64(2920), 'marker': np.int64(1612), 'border': np.int64(306), 'gauss': np.int64(1089), 'macroscopic': np.int64(1581), 'namely': np.int64(1739), 'newton': np.int64(1765), 'geometrical': np.int64(1106), 'traction': np.int64(2725), 'massspring': np.int64(1618), 'sec': np.int64(2352), 'infinitesimal': np.int64(1307), 'separation': np.int64(2373), 'quadrature': np.int64(2093), 'repulsion': np.int64(2226), 'ra': np.int64(2109), 'visc': np.int64(2892), 'impulse': np.int64(1254), 'colliding': np.int64(463), 'disappear': np.int64(743), 'unnoticed': np.int64(2818), 'sharpening': np.int64(2397), 'friendly': np.int64(1071), 'sharpen': np.int64(2396), 'bubble': np.int64(332), 'kll': np.int64(1454), 'vof': np.int64(2904), 'iterate': np.int64(1405), 'indicator': np.int64(1285), 'longer': np.int64(1566), 'hump': np.int64(1199), 'partially': np.int64(1882), 'excess': np.int64(925), 'destroy': np.int64(704), 'pls': np.int64(1955), 'linger': np.int64(1541), 'halt': np.int64(1152), 'bargteil': np.int64(246), 'vanishes': np.int64(2860), 'front': np.int64(1073), 'tangling': np.int64(2644), 'amp': np.int64(110), 'inconsistency': np.int64(1265), 'exacerbate': np.int64(916), 'inaccurate': np.int64(1256), 'comparatively': np.int64(479), 'el': np.int64(836), 'topo': np.int64(2710), 'vital': np.int64(2902), 'generator': np.int64(1104), 'unmodified': np.int64(2813), 'inexpensive': np.int64(1301), 'capillary': np.int64(366), 'clothes': np.int64(443), 'unexplored': np.int64(2798), 'wear': np.int64(2930), 'verlet': np.int64(2876), 'favor': np.int64(993), 'baraff': np.int64(242), 'garment': np.int64(1086), 'robustly': np.int64(2288), 'concentrate': np.int64(514), 'handling': np.int64(1156), 'shirt': np.int64(2404), 'sdd': np.int64(2348), 'classical': np.int64(426), 'regularity': np.int64(2189), 'residual': np.int64(2236), 'skirt': np.int64(2456), 'fabric': np.int64(975), 'volino': np.int64(2907), 'mere': np.int64(1650), 'behind': np.int64(265), 'buckle': np.int64(333), 'modulation': np.int64(1702), 'pragmatic': np.int64(1994), 'lift': np.int64(1521), 'entity': np.int64(880), 'item': np.int64(1403), 'marked': np.int64(1611), 'zone': np.int64(2995), 'scholz': np.int64(2337), 'occlusion': np.int64(1811), 'pant': np.int64(1869), 'print': np.int64(2028), 'pixel': np.int64(1938), 'meshik': np.int64(1656), 'sumner': np.int64(2608), 'bandwidth': np.int64(240), 'megapixel': np.int64(1646), 'magnor': np.int64(1585), 'guskov': np.int64(1149), 'silhouette': np.int64(2420), 'filling': np.int64(1008), 'illumination': np.int64(1224), 'occlude': np.int64(1810), 'lin': np.int64(1533), 'provot': np.int64(2074), 'relax': np.int64(2198), 'anisotropic': np.int64(129), 'notice': np.int64(1788), 'calibration': np.int64(357), 'adequate': np.int64(56), 'lighting': np.int64(1524), 'degrade': np.int64(671), 'sleeve': np.int64(2458), 'ignores': np.int64(1217), 'matlab': np.int64(1624), 'house': np.int64(1194), 'breen': np.int64(321), 'swept': np.int64(2626), 'iz': np.int64(1410), 'cc': np.int64(384), 'bundle': np.int64(343), 'blindly': np.int64(296), 'izs': np.int64(1411), 'ccs': np.int64(385), 'merger': np.int64(1653), 'vicinity': np.int64(2885), 'vol': np.int64(2906), 'hysteretic': np.int64(1206), 'pre': np.int64(1995), 'ebe': np.int64(813), 'kan': np.int64(1432), 'anisotropy': np.int64(130), 'μs': np.int64(2998), 'iter': np.int64(1404), 'centimeter': np.int64(389), 'rungekutta': np.int64(2308), 'reproduction': np.int64(2225), 'drape': np.int64(788), 'draping': np.int64(789), 'cheat': np.int64(408), 'underestimation': np.int64(2789), 'isotropic': np.int64(1401), 'assembly': np.int64(178), 'validate': np.int64(2852), 'textile': np.int64(2672), 'yarn': np.int64(2980), 'limiting': np.int64(1532), 'kawabata': np.int64(1436), 'isolate': np.int64(1399), 'bth': np.int64(330), 'drag': np.int64(786), 'bps': np.int64(315), 'stretching': np.int64(2561), 'cord': np.int64(586), 'stereo': np.int64(2542), 'hysteresis': np.int64(1205), 'woven': np.int64(2969), 'weft': np.int64(2932), 'st': np.int64(2525), 'vk': np.int64(2903), 'plot': np.int64(1954), 'disparity': np.int64(760), 'shearing': np.int64(2399), 'stiffening': np.int64(2545), 'permissible': np.int64(1919), 'timestepping': np.int64(2699), 'clm': np.int64(436), 'inextensibility': np.int64(1302), 'eberhardt': np.int64(814), 'boxerman': np.int64(314), 'hairer': np.int64(1150), 'perceptibly': np.int64(1907), 'shake': np.int64(2391), 'icd': np.int64(1207), 'asymptotically': np.int64(188), 'ii': np.int64(1218), 'attack': np.int64(195), 'aerodynamic': np.int64(73), 'linen': np.int64(1540), 'swatch': np.int64(2625), 'jojic': np.int64(1424), 'triangular': np.int64(2752), 'perceptually': np.int64(1908), 'adi': np.int64(59), 'carignan': np.int64(373), 'ir': np.int64(1396), 'hm': np.int64(1184), 'inner': np.int64(1321), 'alteration': np.int64(99), 'unsymmetric': np.int64(2828), 'wind': np.int64(2950), 'rel': np.int64(2191), 'col': np.int64(456), 'obj': np.int64(1800)}\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=3000)\n",
    "Tfidf_vect.fit(Corpus['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "\n",
    "print(Tfidf_vect.vocabulary_)\n",
    "#print(len(Tfidf_vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fd5b5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(Tfidf_vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50931d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2924)\t0.1390753122926916\n",
      "  (0, 2896)\t0.07412735351588047\n",
      "  (0, 2878)\t0.14905733048510242\n",
      "  (0, 2789)\t0.1390753122926916\n",
      "  (0, 2536)\t0.1390753122926916\n",
      "  (0, 2481)\t0.14563567250311146\n",
      "  (0, 2447)\t0.10095556517591824\n",
      "  (0, 2255)\t0.05748708403031139\n",
      "  (0, 2214)\t0.34507328891429856\n",
      "  (0, 2136)\t0.1390753122926916\n",
      "  (0, 1965)\t0.16312619494728364\n",
      "  (0, 1593)\t0.14251519751370173\n",
      "  (0, 1362)\t0.08501067145083095\n",
      "  (0, 1208)\t0.14905733048510242\n",
      "  (0, 1205)\t0.14905733048510242\n",
      "  (0, 1150)\t0.3262523898945673\n",
      "  (0, 1138)\t0.1390753122926916\n",
      "  (0, 1119)\t0.1390753122926916\n",
      "  (0, 1114)\t0.06585494657367123\n",
      "  (0, 1111)\t0.4893785848418509\n",
      "  (0, 1107)\t0.13170989314734247\n",
      "  (0, 1045)\t0.05509316322579257\n",
      "  (0, 1027)\t0.11502442963809952\n",
      "  (0, 1026)\t0.1390753122926916\n",
      "  (0, 833)\t0.14905733048510242\n",
      "  :\t:\n",
      "  (71, 419)\t0.03419354065603623\n",
      "  (71, 411)\t0.04661514917658631\n",
      "  (71, 408)\t0.04661514917658631\n",
      "  (71, 393)\t0.026636639947414092\n",
      "  (71, 383)\t0.03974233832524088\n",
      "  (71, 335)\t0.0825226095197288\n",
      "  (71, 303)\t0.03974233832524088\n",
      "  (71, 298)\t0.04661514917658631\n",
      "  (71, 297)\t0.13984544752975892\n",
      "  (71, 266)\t0.027320729804690795\n",
      "  (71, 252)\t0.035722001702654355\n",
      "  (71, 250)\t0.032869527473895446\n",
      "  (71, 246)\t0.026636639947414092\n",
      "  (71, 222)\t0.04661514917658631\n",
      "  (71, 221)\t0.09323029835317262\n",
      "  (71, 220)\t0.03752978742134605\n",
      "  (71, 142)\t0.06340333016013566\n",
      "  (71, 140)\t0.03752978742134605\n",
      "  (71, 125)\t0.029711940859873835\n",
      "  (71, 122)\t0.04661514917658631\n",
      "  (71, 95)\t0.02599671662255001\n",
      "  (71, 90)\t0.03170166508006783\n",
      "  (71, 75)\t0.04661514917658631\n",
      "  (71, 21)\t0.04259481255399979\n",
      "  (71, 15)\t0.11922701497572263\n"
     ]
    }
   ],
   "source": [
    "print(Train_X_Tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5df84371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score ->  67.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression(C=1.0, max_iter=100, solver='lbfgs', random_state=42)\n",
    "\n",
    "# Fit the model on the training dataset\n",
    "log_reg.fit(Train_X_Tfidf, Train_Y)\n",
    "\n",
    "# Predict the labels on the validation (test) dataset\n",
    "predictions_log_reg = log_reg.predict(Test_X_Tfidf)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "print(\"Logistic Regression Accuracy Score -> \", accuracy_score(predictions_log_reg, Test_Y) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f190028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  67.3529411764706\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46265b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(Test_Y,predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a8975aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  58.08823529411765\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966465b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08ef0d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_original</th>\n",
       "      <th>text</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[complicated, 3d, character, models, are, wide...</td>\n",
       "      <td>background_claim</td>\n",
       "      <td>[complicated, 3d, character, models, are, wide...</td>\n",
       "      <td>complicated 3d character models are widely use...</td>\n",
       "      <td>['complicate', 'character', 'model', 'widely',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, range, of, breathtaking, realistic, 3d, ...</td>\n",
       "      <td>background_claim</td>\n",
       "      <td>[the, range, of, breathtaking, realistic, 3d, ...</td>\n",
       "      <td>the range of breathtaking realistic 3d models ...</td>\n",
       "      <td>['range', 'breathtaking', 'realistic', 'model'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, production, can, not, afford, major, revis...</td>\n",
       "      <td>background_claim</td>\n",
       "      <td>[a, production, can, not, afford, major, revis...</td>\n",
       "      <td>a production cannot afford major revisions</td>\n",
       "      <td>['production', 'afford', 'major', 'revision']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[providing, a, flexible, and, efficient, solut...</td>\n",
       "      <td>own_claim</td>\n",
       "      <td>[providing, a, flexible, and, efficient, solut...</td>\n",
       "      <td>providing a flexible and efficient solution to...</td>\n",
       "      <td>['provide', 'flexible', 'efficient', 'solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[skeleton, subspace, deformation, (, ssd, ), i...</td>\n",
       "      <td>background_claim</td>\n",
       "      <td>[skeleton, subspace, deformation, (, ssd, ), i...</td>\n",
       "      <td>skeleton subspace deformation (ssd) is the pre...</td>\n",
       "      <td>['skeleton', 'subspace', 'deformation', 'ssd',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text             Label  \\\n",
       "0  [complicated, 3d, character, models, are, wide...  background_claim   \n",
       "1  [the, range, of, breathtaking, realistic, 3d, ...  background_claim   \n",
       "2  [a, production, can, not, afford, major, revis...  background_claim   \n",
       "3  [providing, a, flexible, and, efficient, solut...         own_claim   \n",
       "4  [skeleton, subspace, deformation, (, ssd, ), i...  background_claim   \n",
       "\n",
       "                                       text_original  \\\n",
       "0  [complicated, 3d, character, models, are, wide...   \n",
       "1  [the, range, of, breathtaking, realistic, 3d, ...   \n",
       "2  [a, production, can, not, afford, major, revis...   \n",
       "3  [providing, a, flexible, and, efficient, solut...   \n",
       "4  [skeleton, subspace, deformation, (, ssd, ), i...   \n",
       "\n",
       "                                                text  \\\n",
       "0  complicated 3d character models are widely use...   \n",
       "1  the range of breathtaking realistic 3d models ...   \n",
       "2         a production cannot afford major revisions   \n",
       "3  providing a flexible and efficient solution to...   \n",
       "4  skeleton subspace deformation (ssd) is the pre...   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['complicate', 'character', 'model', 'widely',...  \n",
       "1  ['range', 'breathtaking', 'realistic', 'model'...  \n",
       "2      ['production', 'afford', 'major', 'revision']  \n",
       "3  ['provide', 'flexible', 'efficient', 'solution...  \n",
       "4  ['skeleton', 'subspace', 'deformation', 'ssd',...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60f7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad640f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f348d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data_MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65a8ec9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_original</th>\n",
       "      <th>text</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>['one', 'of', 'the', 'other', 'reviewers', 'ha...</td>\n",
       "      <td>['one', 'reviewer', 'mention', 'watch', 'oz', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>['a', 'wonderful', 'little', 'production', '.'...</td>\n",
       "      <td>['wonderful', 'little', 'production', 'br', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>['i', 'thought', 'this', 'was', 'a', 'wonderfu...</td>\n",
       "      <td>['think', 'wonderful', 'way', 'spend', 'time',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>['basically', 'there', \"'s\", 'a', 'family', 'w...</td>\n",
       "      <td>['basically', 'family', 'little', 'boy', 'jake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>['petter', 'mattei', \"'s\", '``', 'love', 'in',...</td>\n",
       "      <td>['petter', 'mattei', 'love', 'time', 'money', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews     Label  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                       text_original  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. <br /><br />The...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['one', 'of', 'the', 'other', 'reviewers', 'ha...   \n",
       "1  ['a', 'wonderful', 'little', 'production', '.'...   \n",
       "2  ['i', 'thought', 'this', 'was', 'a', 'wonderfu...   \n",
       "3  ['basically', 'there', \"'s\", 'a', 'family', 'w...   \n",
       "4  ['petter', 'mattei', \"'s\", '``', 'love', 'in',...   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['one', 'reviewer', 'mention', 'watch', 'oz', ...  \n",
       "1  ['wonderful', 'little', 'production', 'br', 'b...  \n",
       "2  ['think', 'wonderful', 'way', 'spend', 'time',...  \n",
       "3  ['basically', 'family', 'little', 'boy', 'jake...  \n",
       "4  ['petter', 'mattei', 'love', 'time', 'money', ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"E:/MS_AI_IUB_DATASETS_2022/NLP/preprocessed_data_MS.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0171bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus.drop(['text_final'], axis=1)\n",
    "output_path = 'preprocessed_Text.csv'\n",
    "Corpus.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff782d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_original</th>\n",
       "      <th>text</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>['one', 'of', 'the', 'other', 'reviewers', 'ha...</td>\n",
       "      <td>['one', 'reviewer', 'mention', 'watch', 'oz', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>['a', 'wonderful', 'little', 'production', '.'...</td>\n",
       "      <td>['wonderful', 'little', 'production', 'br', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>['i', 'thought', 'this', 'was', 'a', 'wonderfu...</td>\n",
       "      <td>['think', 'wonderful', 'way', 'spend', 'time',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>['basically', 'there', \"'s\", 'a', 'family', 'w...</td>\n",
       "      <td>['basically', 'family', 'little', 'boy', 'jake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>['petter', 'mattei', \"'s\", '``', 'love', 'in',...</td>\n",
       "      <td>['petter', 'mattei', 'love', 'time', 'money', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews     Label  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                       text_original  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. <br /><br />The...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['one', 'of', 'the', 'other', 'reviewers', 'ha...   \n",
       "1  ['a', 'wonderful', 'little', 'production', '.'...   \n",
       "2  ['i', 'thought', 'this', 'was', 'a', 'wonderfu...   \n",
       "3  ['basically', 'there', \"'s\", 'a', 'family', 'w...   \n",
       "4  ['petter', 'mattei', \"'s\", '``', 'love', 'in',...   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['one', 'reviewer', 'mention', 'watch', 'oz', ...  \n",
       "1  ['wonderful', 'little', 'production', 'br', 'b...  \n",
       "2  ['think', 'wonderful', 'way', 'spend', 'time',...  \n",
       "3  ['basically', 'family', 'little', 'boy', 'jake...  \n",
       "4  ['petter', 'mattei', 'love', 'time', 'money', ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = pd.read_csv(\"E:/MS_AI_IUB_DATASETS_2022/NLP/preprocessed_Text.csv\")\n",
    "pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63e462c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>['one', 'reviewer', 'mention', 'watch', 'oz', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>['wonderful', 'little', 'production', 'br', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>['think', 'wonderful', 'way', 'spend', 'time',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>['basically', 'family', 'little', 'boy', 'jake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>['petter', 'mattei', 'love', 'time', 'money', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                         text_final\n",
       "0  positive  ['one', 'reviewer', 'mention', 'watch', 'oz', ...\n",
       "1  positive  ['wonderful', 'little', 'production', 'br', 'b...\n",
       "2  positive  ['think', 'wonderful', 'way', 'spend', 'time',...\n",
       "3  negative  ['basically', 'family', 'little', 'boy', 'jake...\n",
       "4  positive  ['petter', 'mattei', 'love', 'time', 'money', ..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = pre.drop([\"reviews\", \"text_original\", \"text\"], axis = 1)\n",
    "\n",
    "da.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48883c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'Preprocess.csv'\n",
    "da.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba1e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4628d0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>['one', 'reviewer', 'mention', 'watch', 'oz', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>['wonderful', 'little', 'production', 'br', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>['think', 'wonderful', 'way', 'spend', 'time',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>['basically', 'family', 'little', 'boy', 'jake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>['petter', 'mattei', 'love', 'time', 'money', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                         text_final\n",
       "0  positive  ['one', 'reviewer', 'mention', 'watch', 'oz', ...\n",
       "1  positive  ['wonderful', 'little', 'production', 'br', 'b...\n",
       "2  positive  ['think', 'wonderful', 'way', 'spend', 'time',...\n",
       "3  negative  ['basically', 'family', 'little', 'boy', 'jake...\n",
       "4  positive  ['petter', 'mattei', 'love', 'time', 'money', ..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"E:/MS_AI_IUB_DATASETS_2022/NLP/preprocess.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8eb30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
