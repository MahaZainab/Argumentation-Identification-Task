T1	background_claim 2003 2082	Motion is one of the most important ingredients of CG movies and computer games
T2	background_claim 2084 2185	Obtaining realistic motion usually involves key framing, physically based modelling or motion capture
T3	background_claim 2187 2274	Creating natural looking motions with key framing requires lots of effort and expertise
T4	background_claim 2285 2357	physically based modelling can be applied to simple systems successfully
T5	background_claim 2359 2444	generating realistic motion on a computer is difficult, particularly for human motion
R1	contradicts Arg1:T5 Arg2:T4	
T6	background_claim 2446 2483	A standard solution is motion capture
T9	background_claim 2987 3060	It is very hard to obtain motions that do exactly what the animator wants
T10	background_claim 2763 2806	The biggest drawbacks of motion capture are
T7	background_claim 2619 2687	This allows other CG characters to be animated with the same motions
T11	background_claim 2689 2761	leading to realistic, “human looking” motions for use in movies or games
R2	supports Arg1:T7 Arg2:T11	
T12	background_claim 3062 3158	Satisfying complex timed constraints is difficult and may involve many motion capture iterations
T13	background_claim 2485 2617	motion data for an approximate skeletal hierarchy of the subject is recorded and then used to drive a reconstruction on the computer
T14	data 3177 3239	being at a particular position at a particular time accurately
T15	data 3243 3314	synchronizing movement to a background action that had been shot before
R4	supports Arg1:T14 Arg2:T12	
R5	supports Arg1:T15 Arg2:T12	
T8	background_claim 2817 2870	Most motion capture systems are very expensive to use
T16	data 2880 2920	the process is time consuming for actors
T17	data 2925 2976	technicians and motion data tends not to be re-used
R3	supports Arg1:T16 Arg2:T8	
R6	supports Arg1:T17 Arg2:T8	
T18	background_claim 3372 3414	the motion data needs to be made re-usable
T19	data 3334 3370	make motion capture widely available
R7	supports Arg1:T19 Arg2:T18	
R8	supports Arg1:T8 Arg2:T10	
R9	supports Arg1:T9 Arg2:T10	
R10	supports Arg1:T12 Arg2:T8	
T20	background_claim 3785 3835	There are three natural stages of motion synthesis
T21	data 3430 3488	using previous motion capture data to generate new motions
T22	background_claim 3497 3525	certain requirements are met
R11	supports Arg1:T21 Arg2:T22	
T23	data 3527 3590	transferring motions from one skeletal configuration to another
T24	background_claim 3599 3678	we can animate multiple figures with the same motion without it looking “funny”
R12	supports Arg1:T23 Arg2:T24	
T25	background_claim 3724 3783	the directors can have higher level control over the motion
T26	data 3683 3715	changing the style of the motion
R13	supports Arg1:T26 Arg2:T25	
T27	background_claim 3846 3916	Obtaining motion demands involves specifying constraints on the motion
T28	data 3926 3950	the length of the motion
T29	data 3952 3997	where the body or individual joints should be
T30	data 4001 4052	what the body needs to be doing at particular times
T31	background_claim 4054 4172	These constraints can come from an interactive editing system used by animators, or from a computer game engine itself
R14	supports Arg1:T28 Arg2:T27	
R15	supports Arg1:T29 Arg2:T27	
R16	supports Arg1:T30 Arg2:T27	
R17	supports Arg1:T27 Arg2:T20	
T32	background_claim 4177 4255	Generating motion involves obtaining a rough motion that satisfies the demands
T33	own_claim 4272 4384	we describe a technique that cuts and pastes bits and pieces of example motions together to create such a motion
R18	supports Arg1:T32 Arg2:T20	
T34	background_claim 4389 4452	Post processing involves fixing small scale offensive artifacts
T35	own_claim 4638 4739	we present a framework that allows synthesis of new motion data meeting a wide variety of constraints
T36	own_claim 4741 4817	The synthesized motion is created from example motions at interactive speeds
T37	data 4587 4615	fixing constraint violations
T38	data 4549 4582	lengthening or shortening strides
T39	data 4479 4547	fixing the feet so that they do not penetrate or slide on the ground
R19	supports Arg1:T39 Arg2:T34	
R20	supports Arg1:T38 Arg2:T34	
R21	supports Arg1:T37 Arg2:T34	
R22	supports Arg1:T34 Arg2:T20	
T40	background_claim 4894 4943	motion demands are usually generated by animators
T41	data 4871 4892	In the movie industry
R23	supports Arg1:T41 Arg2:T40	
T42	background_claim 4954 5053	automatic generation of motion demands is required for autonomous intelligent robots and characters
T43	data 5056 5073	Funge et al. 1999
R24	supports Arg1:T43 Arg2:T42	
T44	background_claim 5077 5134	An overview of the automatic motion planning can be found
T45	data 5140 5152	Latombe 1999
T46	data 5154 5167	O’Rourke 1998
R25	supports Arg1:T45 Arg2:T44	
R26	supports Arg1:T46 Arg2:T44	
T47	background_claim 5255 5328	Example based motion synthesis draws on an analogy with texture synthesis
T48	data 5442 5462	Efros and Leung 1999
T49	data 5464 5486	Heeger and Bergen 1995
R27	supports Arg1:T48 Arg2:T47	
R28	supports Arg1:T49 Arg2:T47	
T50	background_claim 5508 5600	used this approach to create cyclic motions by sampling motion signals in a “signal pyramid”
T51	data 5489 5507	Pullen and Bregler
T52	data 5602 5606	2000
R29	parts_of_same Arg1:T51 Arg2:T52	
R30	supports Arg1:T52 Arg2:T50	
T53	background_claim 5609 5721	They also used a similar approach to fetch missing degrees of freedom in a motion from a motion capture database
T54	data 5724 5747	Pullen and Bregler 2002
R31	supports Arg1:T54 Arg2:T53	
T55	background_claim 5750 5865	The sampling can also be done in the motion domain to pick clips of motions to establish certain simple constraints
T57	data 5868 5898	Lamouret and van de Panne 1996
T58	data 5900 5918	Schodl et al. 2000
R32	supports Arg1:T57 Arg2:T55	
T59	data 5335 5439	a new texture (or motion) that looks like an example texture (or motion example) needs to be synthesized
R33	supports Arg1:T59 Arg2:T47	
R35	supports Arg1:T58 Arg2:T55	
T60	background_claim 5922 6017	A roadmap of all the motion examples can be constructed and searched to obtain a desired motion
T61	data 6020 6036	Choi et al. 2000
T62	data 6038 6053	Lee et al. 2002
T63	data 6055 6072	Kovar et al. 2002
R36	supports Arg1:T61 Arg2:T60	
R37	supports Arg1:T62 Arg2:T60	
R38	supports Arg1:T63 Arg2:T60	
T64	background_claim 6076 6176	The clips in this roadmap can also be parameterized for randomly sampling different motion sequences
T65	data 6179 6193	Li et al. 2002
R39	supports Arg1:T65 Arg2:T64	
T66	background_claim 6196 6236	The motion signals can also be clustered
T67	background_claim 6238 6351	The resulting Markov chain can be searched using dynamic programming to find a motion that connects two keyframes
T68	data 6354 6382	Molina-Tanco and Hilton 2000
R40	supports Arg1:T68 Arg2:T67	
T69	background_claim 6388 6445	used in a variable length Markov model to infer behaviors
T70	background_claim 6471 6514	directly sampled from to create new motions
T71	data 6447 6465	Galata et al. 2001
R41	supports Arg1:T71 Arg2:T69	
T72	data 6516 6527	Bowden 2000
T73	own_claim 6531 6558	This is similar to our work
R42	supports Arg1:T72 Arg2:T70	
T74	own_claim 6569 6630	our clustering method does not operate on body configurations
T75	own_claim 6635 6711	our probabilistic search strategy is more effective than dynamic programming
R43	contradicts Arg1:T74 Arg2:T73	
R44	contradicts Arg1:T75 Arg2:T73	
T76	background_claim 6743 6843	Types of probabilistic search algorithms have also been used in physically based animation synthesis
T77	background_claim 6872 6885	and rendering
T78	data 6846 6870	Chenney and Forsyth 2000
T79	data 6887 6908	Veach and Guibas 1997
R45	supports Arg1:T79 Arg2:T77	
R46	supports Arg1:T78 Arg2:T76	
R47	parts_of_same Arg1:T76 Arg2:T77	
T80	background_claim 6911 7087	Controller based approaches use physical models of systems and controllers that produce outputs usually in the form of forces and torques as a function of the state of the body
T81	background_claim 7089 7166	These controllers can be designed specifically to accomplish particular tasks
T82	background_claim 7213 7270	they can be learned automatically using statistical tools
T83	data 7169 7187	Brogan et al. 1998
T84	data 7189 7208	Hodgins et al. 1995
T85	data 7272 7303	Grzeszczuk and Terzopoulos 1995
T86	data 7305 7327	Grzeszczuk et al. 1998
R48	supports Arg1:T83 Arg2:T81	
T56	background_claim 5170 5215	Generating motion largely follows two threads
T87	background_claim 5217 5231	using examples
T88	background_claim 5236 5253	using controllers
R34	supports Arg1:T87 Arg2:T56	
R49	supports Arg1:T88 Arg2:T56	
R50	supports Arg1:T47 Arg2:T87	
R51	supports Arg1:T80 Arg2:T88	
R52	supports Arg1:T84 Arg2:T81	
R53	supports Arg1:T85 Arg2:T82	
T89	data 7329 7341	Mataric 2000
R54	supports Arg1:T86 Arg2:T82	
R55	supports Arg1:T89 Arg2:T82	
T90	background_claim 7344 7477	The motion data can also be post processed to fix problems such as feet sliding on the ground or some constraints not being satisfied
T91	data 7480 7493	Gleicher 1998
T92	data 7495 7512	Lee and Shin 1999
T93	data 7514 7526	Popovic 1999
R56	supports Arg1:T91 Arg2:T90	
R57	supports Arg1:T92 Arg2:T90	
T94	data 7528 7544	Rose et al. 1996
R58	supports Arg1:T93 Arg2:T90	
R59	supports Arg1:T94 Arg2:T90	
T95	background_claim 7547 7638	This usually involves optimization of a suitable displacement function on the motion signal
T96	background_claim 7782 7848	modifying motions appropriately is an interesting research problem
T97	data 7850 7874	Hodgins and Pollard 1997
R60	supports Arg1:T97 Arg2:T96	
T98	background_claim 7715 7780	motion cannot simply be transferred from one body size to another
R61	supports Arg1:T98 Arg2:T96	
T99	data 7640 7700	Different body sizes move according to different time scales
R62	supports Arg1:T99 Arg2:T98	
T100	own_claim 8774 8829	This graph is not a particularly helpful representation
T101	own_claim 8459 8534	The collection of motion sequences could be represented as a directed graph
T102	data 8838 8859	it is extremely large
T103	data 8949 8991	it obscures the structure of the sequences
R63	supports Arg1:T102 Arg2:T100	
R64	supports Arg1:T103 Arg2:T100	
T104	own_claim 9609 9646	the cost attached to the edge is high
T105	data 9518 9602	cutting from one sequence to another along an edge introduces a discontinuous motion
R65	supports Arg1:T105 Arg2:T104	
T106	own_claim 9956 9991	any sequence of edges e 1 · · · e n
T107	own_claim 10093 10148	is a valid path and defines a legal sequence of splices
T109	own_claim 9462 9513	tells us the cost of connecting the incident frames
T110	own_claim 9415 9455	the edges in G are attached a cost value
R66	supports Arg1:T110 Arg2:T109	
T108	data 9254 9274	edges connect frames
T111	own_claim 9276 9331	they are labelled with the frames in the incident nodes
T112	own_claim 9351 9393	that they originate from and they point to
R67	parts_of_same Arg1:T111 Arg2:T112	
R68	supports Arg1:T108 Arg2:T111	
T113	data 9998 10034	toMotion(e i ) = f romMotion(e i+1 )
T114	data 10039 10076	toFrame(e i ) &lt; f romFrame(e i+1 )
T115	data 10078 10080	∀i
T116	data 10082 10092	1≤i &lt; n
T117	data 10151 10159	figure 1
R69	parts_of_same Arg1:T106 Arg2:T107	
T118	data 9939 9954	In this setting
R70	supports Arg1:T113 Arg2:T106	
R71	supports Arg1:T114 Arg2:T106	
R72	supports Arg1:T115 Arg2:T106	
R73	supports Arg1:T116 Arg2:T106	
R74	supports Arg1:T118 Arg2:T106	
R75	supports Arg1:T117 Arg2:T106	
T119	own_claim 10972 11043	We wish to construct paths in the motion graph that satisfy constraints
T120	own_claim 11045 11089	Many constraints cannot be satisfied exactly
T121	background_claim 11337 11425	Typically, a hard constraint involves using a particular frame in a particular time slot
T122	own_claim 11256 11335	We define hard constraints to be those that can (and must) be satisfied exactly
T123	data 11104 11123	given two positions
T124	own_claim 11125 11254	there may not be any sequence of frames in the collection that will get us from the first position to the second position exactly
R76	supports Arg1:T123 Arg2:T124	
R77	supports Arg1:T124 Arg2:T120	
T125	own_claim 11480 11575	we can restrict ourselves to valid paths that pass through particular nodes at particular times
T126	own_claim 11587 11665	we can constrain the moving figure to be at a specific pose at a specific time
R78	supports Arg1:T125 Arg2:T126	
T127	own_claim 11667 11771	This enables us to search for motions such as jumping, falling, or pushing a button at a particular time
T128	own_claim 11773 11822	A soft constraint cannot generally be met exactly
T129	own_claim 11832 11929	we score sequences using an objective function that reflects how well the constraint has been met
T130	own_claim 11934 11968	attempt to find extremal sequences
T131	own_claim 12675 12796	Finding paths in the motion graph that satisfy the hard constraints and optimize soft constraints involves a graph search
T133	data 12817 12851	even a small collection of motions
T134	own_claim 12798 12811	Unfortunately
T132	own_claim 12853 12892	the graph G has a large number of edges
T135	own_claim 12897 12964	straightforward search of this graph is computationally prohibitive
R79	parts_of_same Arg1:T134 Arg2:T132	
R80	supports Arg1:T133 Arg2:T132	
T136	background_claim 13042 13119	many perfectly satisfactory motions that satisfy the constraints equally well
T137	own_claim 12966 13017	The main reason is the need to enumerate many paths
R81	supports Arg1:T137 Arg2:T135	
T138	background_claim 13019 13028	There are
R82	supports Arg1:T138 Arg2:T136	
T140	own_claim 12112 12144	Example soft constraints include
T139	own_claim 12159 12215	The total number of frames should be a particular number
T141	own_claim 12239 12291	To appear in the ACM SIGGRAPH conference proceedings
T142	own_claim 12305 12367	The motion should not penetrate any objects in the environment
T143	own_claim 12372 12452	The body should be at a particular position and orientation at a particular time
T144	own_claim 12550 12568	at a specific time
T145	own_claim 12457 12510	A particular joint should be at a particular position
T146	own_claim 12643 12663	at a particular time
T147	own_claim 12573 12613	The motion should have a specified style
R83	supports Arg1:T139 Arg2:T140	
R84	supports Arg1:T141 Arg2:T140	
R85	supports Arg1:T142 Arg2:T140	
R86	supports Arg1:T143 Arg2:T140	
R87	parts_of_same Arg1:T145 Arg2:T144	
R88	parts_of_same Arg1:T147 Arg2:T146	
R89	supports Arg1:T145 Arg2:T140	
R90	supports Arg1:T147 Arg2:T140	
T148	data 11985 12111	the squared distance between the position of the constraint and the actual position of the body at the time of the constraint.
R91	supports Arg1:T148 Arg2:T129	
T149	own_claim 13273 13326	there are many motions that satisfy these constraints
T150	data 13137 13240	we require only that the person be at one end of a room at frame 0 and near the other end at frame 5000
R92	supports Arg1:T150 Arg2:T149	
T151	own_claim 13396 13459	The motion graph is too hard to search with dynamic programming
T152	own_claim 13463 13531	there are many valid paths that satisfy the constraints equally well
T153	own_claim 13533 13597	There may be substantial differences between equally valid paths
R93	supports Arg1:T152 Arg2:T151	
T154	data 13622 13699	whether you dawdle at one side of the room or the other is of no significance
R94	supports Arg1:T154 Arg2:T153	
T155	own_claim 13701 13804	This suggests summarizing the graph to a higher level and coarser presentation that is easier to search
R95	supports Arg1:T153 Arg2:T155	
T156	own_claim 13806 13853	Branch and bound algorithms are of no help here
T157	data 13863 13894	very little pruning is possible
R96	supports Arg1:T157 Arg2:T156	
T160	own_claim 14286 14359	In such a representation, every level is a summary of the one finer level
T161	own_claim 14162 14284	Coarser levels should have less complexity while allowing us to explore substantially different portions of the path space
T158	data 13905 13945	to search the graph G in practical times
T159	own_claim 13947 14077	we need to do the search at a variety of levels where we do the large scale motion construction first and then “tweak” the details
T162	own_claim 14086 14160	the motion is continuous and satisfies the constraints as well as possible
R97	supports Arg1:T159 Arg2:T162	
R98	supports Arg1:T158 Arg2:T159	
T163	own_claim 15603 15666	there be at least one edge between the corresponding nodes in G
T164	data 15519 15601	there is a cut between two sequences represented by an edge between two nodes in G
R99	supports Arg1:T164 Arg2:T163	
T165	data 15672 15694	this were not the case
T166	own_claim 15696 15738	our summary would rule out potential paths
R100	supports Arg1:T165 Arg2:T166	
T167	own_claim 15210 15279	most probably their preceding and succeeding frames also look similar
T168	data 15186 15208	two frames are similar
T169	own_claim 15015 15032	The cost function
T170	own_claim 15056 15139	causes the P matrices to have non-infinite entries to form nearly elliptical groups
R101	parts_of_same Arg1:T169 Arg2:T170	
R102	supports Arg1:T168 Arg2:T167	
T171	data 15046 15055	section A
T172	data 15142 15150	figure 2
R103	supports Arg1:T171 Arg2:T169	
R104	supports Arg1:T172 Arg2:T170	
R105	supports Arg1:T167 Arg2:T170	
T173	own_claim 16543 16637	We would like to have a tree of graph representations whose root is G , and whose leaves are G
T174	background_claim 16826 16884	This is an instance of Tree-Structured Vector Quantization
T175	data 16887 16907	Gersho and Gray 1992
R106	supports Arg1:T175 Arg2:T174	
T176	data 16916 16941	in our summarized graph G
T177	own_claim 16944 17061	each edge is the root of a binary tree and represents all the edges in close neighborhood in terms of the edge labels
R107	supports Arg1:T176 Arg2:T177	
T178	own_claim 18458 18565	we would like to be able to generate different alternative motions that achieve the same set of constraints
T179	data 18430 18456	While searching this graph
R108	supports Arg1:T179 Arg2:T178	
T180	own_claim 18704 18734	This motivates a random search
T181	own_claim 18567 18667	During the search, we need to find paths close to optimal solutions but do not require exact extrema
T182	data 18677 18702	they are too hard to find
R109	supports Arg1:T182 Arg2:T181	
R110	supports Arg1:T181 Arg2:T180	
T183	own_claim 19413 19423	better one
T184	own_claim 19338 19400	Intuitively the first mutation strategy replaces a clip with a
R111	parts_of_same Arg1:T184 Arg2:T183	
T185	own_claim 19428 19504	the second mutation strategy adjusts the detailed position of cut boundaries
T186	own_claim 19512 19563	we start new random “seed” paths at every iteration
T187	own_claim 19565 19624	the algorithm does not get stuck at a local optimum forever
R112	supports Arg1:T186 Arg2:T187	
T188	data 19626 19639	Section 4.2.2
R113	supports Arg1:T188 Arg2:T187	
T189	own_claim 19681 19719	Hard constraints are easily dealt with
T190	own_claim 19721 19780	we restrict our search to paths that meet these constraints
T191	background_claim 19792 19826	hard constraints specify the frame
T192	background_claim 19850 19881	to be used at a particular time
R114	supports Arg1:T191 Arg2:T192	
T193	own_claim 19883 19981	We do this by ensuring that “seed” paths meet these constraints, and mutations do not violate them
T194	own_claim 20189 20254	a graph search can also be performed between the constraint nodes
T195	data 20148 20187	the path is sampled at the coarse level
R115	supports Arg1:T195 Arg2:T194	
R116	supports Arg1:T190 Arg2:T189	
T196	own_claim 20432 20472	the underlying motion graph is connected
T197	own_claim 20554 20594	this algorithm is similar to MCMC search
T198	data 20647 20664	Gilks et al. 1996
R117	supports Arg1:T198 Arg2:T197	
T199	own_claim 20366 20405	Such mutations are rejected immediately
T200	own_claim 20677 20796	it is difficult to compute proposal probabilities for the mutations we use, which are strikingly successful in practice
T201	own_claim 20798 20857	This is an online algorithm which can be stopped at anytime
T202	data 20888 20975	edges in intermediate graphs G · · · G n also represent connections and are valid edges
R118	supports Arg1:T202 Arg2:T201	
T203	own_claim 20982 21050	we do not have to reach the leaf graph G to be able to create a path
T204	own_claim 21070 21165	We can stop the search iteration, take the best path found so far, and create a motion sequence
R119	supports Arg1:T201 Arg2:T203	
T205	data 21170 21201	the sequence is not good enough
T206	own_claim 21203 21318	we can resume the search from where we left off to get better paths through mutations and inclusion of random paths
T207	own_claim 21320 21382	This allows an intuitive computation cost vs. quality tradeoff
R120	supports Arg1:T205 Arg2:T206	
R121	supports Arg1:T206 Arg2:T207	
R122	supports Arg1:T203 Arg2:T204	
T208	own_claim 21542 21580	these constraints are always satisfied
T209	data 21458 21540	during the search all the paths live in a subspace implied by the hard constraints
R123	supports Arg1:T209 Arg2:T208	
T210	own_claim 21624 21676	we score the path using the imposed soft constraints
T211	data 21582 21621	Given a sequence of edges e 1 · · · e n
R124	supports Arg1:T211 Arg2:T210	
T212	own_claim 21699 21783	we compute a cost where the cost is indicative of the satisfaction of the constraint
T213	data 21678 21697	For each constraint
R125	supports Arg1:T213 Arg2:T212	
T214	own_claim 22054 22151	The weights can be manipulated to increase/decrease the influence of a particular soft constraint
T215	own_claim 24267 24312	The first body constraint is always satisfied
T216	data 24322 24397	we always start putting the motions together from the first body constraint
R126	supports Arg1:T216 Arg2:T215	
T217	own_claim 26530 26666	Doing this mutation on two edges simultaneously allows us to compensate for the errors that would happen if only one of them was demoted
T218	own_claim 26824 26855	this step is not very expensive
T219	data 26757 26822	the summary has significantly fewer edges than the original graph
R127	supports Arg1:T219 Arg2:T218	
T220	own_claim 27061 27132	we can obtain multiple motions that satisfy the same set of constraints
T221	data 27051 27059	This way
R128	supports Arg1:T221 Arg2:T220	
T222	background_claim 27527 27613	at the frames corresponding to the edges in the path, we will have C 0 discontinuities
T223	data 27626 27681	the finite number of motions sampling an infinite space
R129	supports Arg1:T223 Arg2:T222	
T224	own_claim 27683 27804	In practice these discontinuities are small and we can distribute them within a smoothing window around the discontinuity
T225	own_claim 29479 29569	these “smoothing” steps can cause artifacts like feet penetrating or sliding on the ground
T226	own_claim 29580 29691	usually the errors made in terms of constraints and the discontinuities are so small that they are unnoticeable
R130	contradicts Arg1:T226 Arg2:T225	
T227	own_claim 29825 29886	we are able to synthesize human looking motions interactively
T228	data 29779 29823	Using iterative improvements of random paths
R131	supports Arg1:T228 Arg2:T227	
T229	own_claim 29888 29943	This allows interactive manipulation of the constraints
R132	supports Arg1:T227 Arg2:T229	
T230	own_claim 29945 29962	This is important
T231	data 29972 30086	motion synthesis is inherently ambiguous as there may be multiple motions that satisfy the same set of constraints
R133	supports Arg1:T231 Arg2:T230	
T232	own_claim 30088 30176	The algorithm can find these “local minimum” motions that adhere to the same constraints
T233	own_claim 30178 30294	The animator can choose between them or all the different motions can be used to create a variety in the environment
T234	own_claim 30332 30421	the animator can also see the ambiguity and guide the search by putting extra constraints
T235	data 30424 30432	figure 6
T236	data 30302 30330	the algorithm is interactive
R134	supports Arg1:T236 Arg2:T234	
R135	supports Arg1:T235 Arg2:T234	
T237	own_claim 30436 30547	Currently, we can constrain the length of the motion, the body’s position and orientation at a particular frame
T238	own_claim 30564 30571	a joint
T239	own_claim 30590 30633	to a particular state at a particular frame
T240	own_claim 30651 30705	constrain the entire body’s pose at a particular frame
R136	parts_of_same Arg1:T238 Arg2:T239	
R137	parts_of_same Arg1:T237 Arg2:T238	
T241	data 30550 30558	figure 5
T242	data 30560 30561	6
T243	data 30578 30582	head
T244	data 30584 30588	hand
T245	data 30636 30644	figure 7
R138	supports Arg1:T241 Arg2:T237	
R139	supports Arg1:T242 Arg2:T237	
R140	supports Arg1:T243 Arg2:T238	
R141	supports Arg1:T244 Arg2:T238	
R142	supports Arg1:T245 Arg2:T239	
T246	data 30707 30715	figure 8
R143	supports Arg1:T246 Arg2:T240	
T247	own_claim 30730 30813	we can synthesize multiple interacting motions independently using hard constraints
T248	data 30816 30824	figure 9
T249	data 30828 30910	we simply select the poses, position and orientation at which the figures interact
T250	own_claim 30915 30957	this framework fills in the missing motion
T251	own_claim 30971 31000	interpolating the constraints
R144	semantically_same Arg1:T250 Arg2:T251	
R145	supports Arg1:T249 Arg2:T250	
R146	supports Arg1:T250 Arg2:T247	
R147	supports Arg1:T248 Arg2:T247	
T252	own_claim 31002 31065	These are only a few of the constraints that can be implemented
T253	own_claim 31223 31263	many more constraints can be implemented
R148	semantically_same Arg1:T253 Arg2:T252	
T254	data 31078 31136	the user specifies a cost function that evaluates a motion
T255	data 31141 31221	attaches a score that is indicative of the animator’s satisfaction with the path
R149	supports Arg1:T255 Arg2:T253	
R150	supports Arg1:T254 Arg2:T253	
T256	own_claim 31364 31477	we can also constrain the style of the desired motion by penalizing motions that do not have the particular style
R151	supports Arg1:T256 Arg2:T253	
T257	data 31281 31362	the motions in our database are marked with their individual stylistic attributes
R152	supports Arg1:T257 Arg2:T256	
T258	own_claim 31511 31588	we can constrain the synthesized motion to avoid obstacles in the environment
T259	own_claim 31606 31689	body position/orientation constraints can also come from an underlying path planner
T260	data 31479 31509	In a computer game environment
R153	supports Arg1:T260 Arg2:T258	
T261	data 31590 31604	In such a case
R154	supports Arg1:T261 Arg2:T259	
T262	own_claim 31765 31817	human looking motions can be generated automatically
T263	data 31697 31719	given high level goals
R155	supports Arg1:T263 Arg2:T262	
R156	supports Arg1:T259 Arg2:T262	
T264	own_claim 32242 32374	We have presented a framework that allows interactive synthesis of natural looking motions that adhere to user specified constraints
T265	own_claim 32428 32450	the motion looks human
T266	own_claim 32462 32583	the motions generated by the method do not have unnatural artifacts such as slipping feet on the ground or jerky movement
T267	own_claim 32592 32636	the user specified constraints are satisfied
T268	data 32643 32707	the motion passes through the required spot at the required time
R157	supports Arg1:T268 Arg2:T267	
T269	data 32712 32756	the character falls to a particular position
T270	data 32759 32767	figure 8
R158	supports Arg1:T269 Arg2:T267	
R159	supports Arg1:T270 Arg2:T267	
T271	own_claim 32780 32815	motions are generated interactively
T272	background_claim 32874 32958	an acceptable 300 frame motion is found in between 3 and 10 seconds on an average PC
T273	data 32828 32872	depending on the quality of the path desired
R160	supports Arg1:T273 Arg2:T272	
T274	own_claim 32985 33031	This speed allows interactive motion authoring
R161	supports Arg1:T272 Arg2:T274	
T275	background_claim 33205 33267	The average precomputation time required for this many motions
T276	background_claim 33297 33328	is 5 hours on the same computer
R162	parts_of_same Arg1:T275 Arg2:T276	
T278	own_claim 33431 33469	This framework is completely automatic
T280	own_claim 33508 33593	the computation of the hierarchic motion graph does not require any user intervention
T281	data 33476 33506	the input motions are selected
R164	supports Arg1:T281 Arg2:T280	
T282	own_claim 33653 33731	For many kinds of constraints the motion synthesis problem is underconstrained
T283	own_claim 33598 33651	the resulting representation is searched in real-time
R165	supports Arg1:T281 Arg2:T283	
T284	data 33733 33827	there are many possible combinations of motion pieces that achieve the same set of constraints
T285	own_claim 33829 33921	Randomized search is well suited to find many different motions that satisfy the constraints
R166	supports Arg1:T284 Arg2:T282	
T286	own_claim 33942 33988	some constraints, may not be met by any motion
R167	contradicts Arg1:T286 Arg2:T285	
T287	own_claim 34004 34093	randomized search will try to minimize our objective motion and find the “closest” motion
T288	data 33990 34002	In this case
R168	supports Arg1:T288 Arg2:T287	
T289	own_claim 34154 34261	the algorithm will tend to put fast running motions together but not necessarily satisfying the constraints
T290	data 34111 34152	the user asks for 100 meters in 5 seconds
R169	supports Arg1:T290 Arg2:T289	
T291	own_claim 34341 34411	the algorithm will perform searches confined to the unconnected graphs
T292	data 34277 34339	the set of motions to begin with do not form a connected graph
R170	supports Arg1:T292 Arg2:T291	
T293	data 34416 34478	there are hard constraints in different unconnected components
T294	own_claim 34480 34532	we will not even be able to find starting seed paths
R171	supports Arg1:T293 Arg2:T294	
T295	own_claim 34557 34612	the selection of the database to work with is important
T296	own_claim 34759 34858	the randomized search has no problem finding rare motions that turn back to satisfy the constraints
T277	data 33330 33429	On average, the results shown in the video contain 3-30 motion pieces cut from the original motions
R163	supports Arg1:T277 Arg2:T274	
T297	data 35003 35011	figure 9
T279	own_claim 34860 34910	The motion databases that we used were unorganized
R172	supports Arg1:T297 Arg2:T279	
T298	own_claim 35015 35114	The randomized search scales linearly as a function of the database size with a very small constant
T299	own_claim 35116 35221	We have tried datasets of 50-100 motions without a noticeable change in the running time of the algorithm
T300	own_claim 35223 35340	The linearity in the running time comes from the linear increase in the number of alternative mutations at every step
T301	data 35355 35384	the database size gets larger
T302	own_claim 35386 35400	the constant τ
T303	own_claim 35414 35460	that is used to create the edges can get lower
T304	data 35402 35412	Appendix A
R173	parts_of_same Arg1:T302 Arg2:T303	
R174	supports Arg1:T304 Arg2:T302	
T305	own_claim 35467 35574	more motions mean that we expect to find better connections between motions, decreasing the number of edges
R175	supports Arg1:T301 Arg2:T302	
R176	supports Arg1:T305 Arg2:T303	
T306	own_claim 35576 35634	This will lead to a sublinear increase in the running time
T307	own_claim 35636 35680	The framework can work on any motion dataset
R177	supports Arg1:T303 Arg2:T306	
T308	own_claim 35682 35772	it can be created by traditional key framing, physically based modelling or motion capture
R178	supports Arg1:T308 Arg2:T307	
T309	own_claim 35787 35826	we can take the motion data for “Woody”
T310	own_claim 35864 35925	from “Toy Story” and create new “Woody” motions automatically
R179	parts_of_same Arg1:T309 Arg2:T310	
T311	own_claim 35927 35991	The framework is also appli- cable to non-human motion synthesis
R180	supports Arg1:T309 Arg2:T307	
T312	own_claim 36006 36180	this framework can be used to generate control signals for robots to achieve a particular task by generating the motion graph for previously known motion-control signal pairs
R181	supports Arg1:T312 Arg2:T311	
T313	own_claim 36408 36478	the resulting motions will also carry the underlying style of the data
T314	own_claim 36182 36320	During the synthesis we can not only synthesize the final robot motion but also the associated control signals that achieve specific goals
T315	data 36328 36406	the generated motions are obtained by putting pieces of motions in the dataset
R182	supports Arg1:T315 Arg2:T313	
T316	own_claim 36490 36603	we can take the motion data for one character, and produce more motions with the intrinsic style of the character
T317	background_claim 37045 37172	During the construction of the final motion, better ways of smoothing between adjacent motions could be used to improve realism
T318	data 37175 37187	Popovic 1999
R183	supports Arg1:T318 Arg2:T317	
T319	own_claim 37220 37319	motions could also be synthesized on non-uniform surfaces which the current framework cannot handle
T320	data 37190 37218	Using better post processing
R184	supports Arg1:T320 Arg2:T319	
T321	own_claim 37321 37451	Additional post processing may involve physically based modelling to make sure the synthesized motions are also physically correct
T323	background_claim 37640 37753	By analyzing patterns in the motion dataset, we might also infer these styles or obtain higher level descriptions
T322	own_claim 37453 37638	Automatic integration of higher level stylistic constraints could be incorporated into the framework, avoiding the arduous job of labelling every motion with the intrinsic style by hand
T324	data 37755 37779	Brand and Hertzmann 2001
R185	supports Arg1:T324 Arg2:T323	
T325	own_claim 37782 37883	The synthesized motions are strictly bound to the motions that were available in the original dataset
T326	own_claim 37894 38054	it is conceivable that the motions that are very close to the dataset could also be incorporated in the synthesizable motions using learned stylistic variations
R186	contradicts Arg1:T326 Arg2:T325	
T327	own_claim 38056 38148	The integrity of the original dataset directly effects the quality of the synthesized motion
T328	own_claim 38239 38308	we will not be able to synthesize motions that involve “turning left”
T329	data 38166 38237	the incoming motion dataset does not contain any “turning left” motions
R187	supports Arg1:T329 Arg2:T328	
T330	own_claim 38310 38519	An automatic way of summarizing the portions of the “possible human motions” space that have not been explored well enough by the dataset could improve the data gathering and eventually the synthesized motions
T331	own_claim 38521 38567	This could also serve as a palette for artists
T332	own_claim 38696 38789	the animator could interactively select the motions that need to be used during the synthesis
T333	data 38569 38682	some portions of the precomputed motion graph can be paged in and out of memory depending on the required motion.
T334	own_claim 38879 38978	This would give animators a tool whereby they can select the set of motions to work with in advance
T335	own_claim 39062 39113	this encourages comprehensive re-use of motion data
T336	own_claim 38795 38877	only the portion of the motion graph involving the desired motions could be loaded
R188	supports Arg1:T332 Arg2:T336	
T337	own_claim 38983 39048	the new motions will be created only from the artist selected set
R189	supports Arg1:T334 Arg2:T337	
R190	supports Arg1:T331 Arg2:T332	
R191	supports Arg1:T336 Arg2:T334	
